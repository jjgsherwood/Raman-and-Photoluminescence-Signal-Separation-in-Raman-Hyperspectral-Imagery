{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6e2a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.dataset_utils as dataset\n",
    "import utils.train_utils as train\n",
    "\n",
    "from os import path\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2a964",
   "metadata": {},
   "source": [
    "# USE KALMAN FILTER TO SMOOTH RESULT\n",
    "\n",
    "### Is FFT or DCT more stable with gradient descent?\n",
    "#### weight normalization?\n",
    "#### seperate training of the last layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6a6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector_norm(X):\n",
    "    return (X.T / np.sqrt((X**2).sum(axis=1))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b327873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE = False\n",
    "# file_location = \"../data/Raman_Mouse/approximated_curve_fit/\"\n",
    "# file_location_org = \"../data/Raman_Mouse/corrected_4_wavenumbers/\"\n",
    "# filenames = np.load(f\"{file_location}FileNames.npy\")\n",
    "# with open(f'../data/Raman_Mouse/Sample_labels.pickle', 'rb') as f:\n",
    "#     labels = pickle.load(f)\n",
    "\n",
    "# vector_norm = unit_vector_norm if NORMALIZE else lambda x: x\n",
    "    \n",
    "# data = []\n",
    "# for f in filenames:\n",
    "#     raw = np.load(f\"{file_location_org}{f.split('.')[0]}.npy\")\n",
    "#     raman = np.load(f\"{file_location}{f.split('.')[0]}_raman.npy\")\n",
    "#     photo = np.load(f\"{file_location}{f.split('.')[0]}_photoluminescence.npy\")\n",
    "    \n",
    "#     if np.sum(np.isnan(raman)) or np.sum(np.isnan(photo)):\n",
    "#         print(f, np.sum(np.isnan(raman)), np.sum(np.isnan(photo)))\n",
    "#         continue\n",
    "        \n",
    "# #     raw = np.concatenate((raw[:,:,::2], raw[:,:,::-2]), 2)\n",
    "# #     raman = np.concatenate((raman[:,:,::2], raman[:,:,::-2]), 2)\n",
    "# #     photo = np.concatenate((photo[:,:,::2], photo[:,:,::-2]), 2)\n",
    "        \n",
    "#     data.append((vector_norm(raw.reshape(-1,raw.shape[-1])).reshape(raw.shape),\n",
    "# #                  vector_norm(raw.reshape(-1,raw.shape[-1])).reshape(raw.shape),\n",
    "# #                  vector_norm(raw.reshape(-1,raw.shape[-1])).reshape(raw.shape),\n",
    "# #                  vector_norm((raman+photo).reshape(-1,raman.shape[-1])).reshape(raman.shape),\n",
    "#                  vector_norm(raman.reshape(-1,photo.shape[-1])).reshape(photo.shape), \n",
    "#                  vector_norm(photo.reshape(-1,photo.shape[-1])).reshape(photo.shape), \n",
    "# #                  vector_norm(raw.reshape(-1,raw.shape[-1])).reshape(raw.shape),\n",
    "#                  labels[f]))\n",
    "# #     data.append((raw,\n",
    "# #                  raman,\n",
    "# #                  vector_norm(photo.reshape(-1,photo.shape[-1])).reshape(photo.shape), \n",
    "# #                  labels[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7bfb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  91.71582031,   93.27603023,   94.83624014, ..., 2041.97821298,\n",
       "       2043.5384229 , 2045.09863281])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DESKTOP\n",
    "# file_locations = [\"../data/Raman_Mouse/photoluminences_2022-11-30 12-16-25.050493/\",\n",
    "#                  \"../data/Raman_Mouse/raman_2022-11-30 12-16-11.285597/\",\n",
    "#                  \"../data/Raman_Mouse/preprocessed_2022-11-30 11-48-26.672496/\"]\n",
    "# LAPTOP\n",
    "file_locations = [\"../data/Raman_Mouse/photoluminences_2022-11-30 12-16-25.050493/\",\n",
    "                 \"../data/Raman_Mouse/raman_2022-11-30 12-16-11.285597/\",\n",
    "                 \"../data/Raman_Mouse/preprocessed_2022-12-01 11-53-44.127304/\"]\n",
    "\n",
    "filenames = [glob.glob(file_location+'/[!Wave|File]*.npy') for file_location in file_locations]\n",
    "# with open(f\"{'/'.join(file_location.split('/')[:-2])}/Sample_labels.pickle\", 'rb') as f:\n",
    "#     labels = pickle.load(f)\n",
    "# labels = {l.split(\".\")[0]: val for l, val in labels.items()}\n",
    "\n",
    "wavenumbers = np.load(f\"{file_locations[2]}Wavenumbers.npy\")\n",
    "NORM = False\n",
    "# func = unit_vector_norm if NORM else lambda x:x\n",
    "    \n",
    "# data = []\n",
    "# for f in filenames:\n",
    "#     x = np.load(f)\n",
    "#     data.append((func(x.reshape(-1,x.shape[-1])).reshape(x.shape),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484b262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ReLU\n",
    "nn.GELU\n",
    "nn.LeakyReLU\n",
    "nn.ELU\n",
    "\n",
    "\"\"\"\n",
    "Keep sum of weights positive,\n",
    "imag part must be zero (loss function)\n",
    "\"\"\"\n",
    "\n",
    "class Conv_FFT(nn.Module):\n",
    "    def __init__(self, num_input_channels : int = 2, base_channel_size: int = 16, act_fn : object = nn.GELU, groups : int = 2, **kwargs):\n",
    "        super().__init__()\n",
    "        c_hid = base_channel_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(num_input_channels, c_hid, kernel_size=11, padding=5, groups=groups, bias=False), \n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid, c_hid, kernel_size=9, padding=4, groups=groups, bias=False),\n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid, c_hid, kernel_size=7, padding=3, groups=2*groups, bias=False),\n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid, c_hid, kernel_size=5, padding=2, groups=2*groups, bias=False),\n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid, 2*num_input_channels, kernel_size=3, padding=1, groups=2*groups, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.smooth = nn.Sequential(\n",
    "            nn.Conv1d(1, 1, kernel_size=31, padding=15, groups=1, bias=False), \n",
    "#             act_fn(),\n",
    "#             nn.Conv1d(c_hid, 1, kernel_size=5, padding=2, groups=1), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        d = 1\n",
    "#         x = torch.cat((x, torch.flip(x, (1,)), x, torch.flip(x, (1,))), 1)\n",
    "#         x = torch.fft.fft(x, dim=d, norm='backward')\n",
    "        x = torch.fft.rfft(x, dim=d, norm='backward')\n",
    "        x = torch.stack((x.real, x.imag), 1)\n",
    "        x = self.net(x)\n",
    "        x1, x2 = x[:,[0,2]], x[:,[1,3]]\n",
    "        x1, x2 = torch.transpose(x1, -2, -1).contiguous(), torch.transpose(x2, -2, -1).contiguous()\n",
    "        x1, x2 = torch.view_as_complex(x1), torch.view_as_complex(x2)\n",
    "#         x1, x2 = torch.fft.ifft(x1, dim=d, norm='backward').real[:,None,:], torch.fft.ifft(x2, dim=d, norm='backward').real\n",
    "        x1, x2 = torch.fft.irfft(x1, dim=d, norm='backward')[:,None,:], torch.fft.irfft(x2, dim=d, norm='backward')\n",
    "#         x1, x2 = torch.fft.irfft(x1, dim=d, norm='backward')[:,None,2600:3900], torch.fft.irfft(x2, dim=d, norm='backward')[:,2600:3900]\n",
    "#         return x1, x2\n",
    "        return F.relu(self.smooth(x1).reshape(x.shape[0],-1)), F.relu(x2)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = x.reshape(-1, 1, x.shape[-1])\n",
    "#         x = self.net(x).reshape(x.shape[0],-1)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedClassifier(BaseEstimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        _use_cuda = torch.cuda.is_available() and kwargs['cuda']\n",
    "        if _use_cuda:\n",
    "            torch.backends.cudnn.enabled = True\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        self.device = torch.device('cuda' if _use_cuda else 'cpu')        \n",
    "        print(f\"device: {self.device}\")\n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.model = Conv_FFT().to(self.device)\n",
    "        \n",
    "        parameters = filter(lambda x: x.requires_grad, self.model.parameters())\n",
    "        self.optimizer = optim.Adam(parameters, lr=self.kwargs['lr'])                \n",
    "        train_loader, test_loader = dataset.load_splitdata(data, self.kwargs['batch_size'])\n",
    "        \n",
    "        for epoch in range(self.kwargs['epochs']):\n",
    "#             if path.exists(f\"Conv_FFT_model_epoch{epoch}.pt\"):\n",
    "#                 print(f\"epoch {epoch} is already trained\")\n",
    "#                 if not path.exists(f\"Conv_FFT_model_epoch{epoch+1}.pt\"):\n",
    "#                     self.model = torch.load(f\"Conv_FFT_model_epoch{epoch}.pt\")\n",
    "#                 continue \n",
    "            if epoch == 1:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = 0.005  \n",
    "            elif epoch == 5:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = 0.001\n",
    "            elif epoch == 10:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = 0.0001\n",
    "            print('-'*50)\n",
    "            print('Epoch {:3d}/{:3d}'.format(epoch+1, self.kwargs['epochs']))\n",
    "            start_time = datetime.now()\n",
    "            train.train(self.model, self.optimizer, train_loader, self.kwargs['loss_func'], self.kwargs['acc_func'], self.kwargs['log_step'], self.device)\n",
    "            end_time = datetime.now()\n",
    "            time_diff = relativedelta(end_time, start_time)\n",
    "            print('Elapsed time: {}h {}m {}s'.format(time_diff.hours, time_diff.minutes, time_diff.seconds))\n",
    "            train.test(self.model, test_loader, self.kwargs['loss_func'], self.kwargs['loss_func'], self.device)\n",
    "#             torch.save(self.model, f\"Conv_FFT_model_epoch{epoch}.pt\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict transforms the data into the reference space. Min weight should be 0 or higher then 'min_weight'\n",
    "        The error is the NMSE, where the MSE is normalised by the signal strength. \n",
    "        error.shape = X.shape[0], so for each data point the error is calculated.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "#         self.model(X)\n",
    "        \n",
    "#         return RCA_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6509fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "loss2 = nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n",
    "# loss3 = nn.KLDivLoss(size_average=None, reduce=None, reduction='batchmean', log_target=False)\n",
    "# both closely related\n",
    "# loss4 = nn.HuberLoss(reduction='mean', delta=100.0)\n",
    "# loss5 = nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean', beta=1.0)\n",
    "\n",
    "def loss_func(y, y_, x):\n",
    "    raman, photo, _ = y\n",
    "    raman = raman.to(y_[0].device)\n",
    "    photo = photo.to(y_[0].device)\n",
    "    return loss2(y_[0], photo) + loss2(y_[1], raman) #+ torch.mean(torch.sum(F.relu(y_[0] + y_[1] - x), 1)) # + loss1(y_[0] + y_[1], x)\n",
    "\n",
    "def acc_func(y, y_, x):\n",
    "    y_1, y_2 = y_\n",
    "    y_1, y_2 = y_1.cpu().detach().numpy(), y_2.cpu().detach().numpy()\n",
    "    plt.plot(x[0], label='raw')\n",
    "    plt.plot(y_1[0] + y_2[0], label='raw')\n",
    "    plt.show()\n",
    "    plt.plot(x[0], label='raw')\n",
    "    plt.plot(y[0][0], label='raman')\n",
    "    plt.plot(y[1][0], label='photo')\n",
    "    plt.plot(y_1[0], label='Conv1')\n",
    "    plt.plot(y_2[0], label='Conv2')\n",
    "    plt.ylim(ymin=-10)\n",
    "    plt.xlim(xmin=0, xmax=1300)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return loss_func(y, y_, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25\n",
    "\n",
    "kwargs = {'batch_size': BATCH_SIZE,\n",
    "          'cuda': True,\n",
    "          'log_step': 500,\n",
    "          'epochs': EPOCHS,\n",
    "          'loss_func': loss_func,\n",
    "          'acc_func' : acc_func,\n",
    "          'bias': True,\n",
    "          'lr': 0.001\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703feef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rvc = SupervisedClassifier(**kwargs)\n",
    "rvc.fit(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183e89f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4644f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
