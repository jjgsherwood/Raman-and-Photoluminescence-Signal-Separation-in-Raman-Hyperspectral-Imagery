{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e2a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import utils.dataset_utils as dataset\n",
    "import utils.train_utils as train\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "plt.rcParams['lines.linewidth'] = 0.75\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f001399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ada2a964",
   "metadata": {},
   "source": [
    "#### USE KALMAN FILTER TO SMOOTH RESULT? Not necessary\n",
    "\n",
    "#### Is FFT or RFFT more stable with gradient descent? Equally stable RFFT is just faster\n",
    "#### weight normalization?\n",
    "#### seperate training of the last layer? Yes\n",
    "#### Use different padding (first make the signal bigger than smaller)?\n",
    "\n",
    "#### Use CNN or GRU to smooth the output? Gru does not work\n",
    "#### Does RAMAN also need smoothing? Yes\n",
    "#### tiny no hidden layers seems to work a bit less good than with hidden layers. One difference is that the photo is not as smooth.\n",
    "#### larger CNN seems to train faster, but they risk overfitting\n",
    "\n",
    "#### Pretraining works better than not pretraining.\n",
    "\n",
    "#### Dependency tests:\n",
    "Raw, photo or raman to Raman with CNN does not work\n",
    "\n",
    "Training Raman from Raw+Photo from start does work.\n",
    "\n",
    "Training Raman from Raw+Raman from start gives weird intermediate results but does work. When using pretraining it seems to give better results at least for the intermediate results.\n",
    "\n",
    "Training Raman from Photo+Raman does work with pretraining (can not be trained from start)\n",
    "\n",
    "Training Raman from All does work.\n",
    "\n",
    "Training Photo from Raw does not work.\n",
    "\n",
    "Training Photo and Raman from raw does not work, but it seems to work better than when they are seperatly trained from raw (however the network used was bigger)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector_norm(X):\n",
    "    return (X.T / np.sqrt((X**2).sum(axis=1))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bfb4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DESKTOP\n",
    "file_locations = [\"../data/Raman_Mouse/preprocessed_2022-11-30 11-48-26.672496/\",\n",
    "                  \"../data/Raman_Mouse/raman_2022-11-30 12-16-11.285597/\",\n",
    "                  \"../data/Raman_Mouse/photoluminences_2022-11-30 12-16-25.050493/\"]\n",
    "# LAPTOP\n",
    "# file_locations = [\"../data/Raman_Mouse/preprocessed_2022-12-01 11-53-44.127304/\",\n",
    "#                   \"../data/Raman_Mouse/raman_2022-12-01 12-13-34.452351/\",\n",
    "#                   \"../data/Raman_Mouse/photoluminences_2022-12-01 12-13-35.526177/\"]\n",
    "# filenames = [sorted(glob.glob(file_location+'/[!Wave|!Liver|!Kidney]*.npy')) for file_location in file_locations]\n",
    "# filenames = [sorted(glob.glob(file_location+'/[!Wave|!muscle]*.npy')) for file_location in file_locations]\n",
    "filenames = [sorted(glob.glob(file_location+'/[!Wave]*.npy')) for file_location in file_locations]\n",
    "\n",
    "saved_NN = \"saved_NN_photo_only_raman_all_pre\"\n",
    "os.makedirs(saved_NN, exist_ok=True)\n",
    "\n",
    "basenames = [[os.path.splitext(os.path.basename(f))[0] for f in filename] for filename in filenames]\n",
    "\n",
    "# check if all files exist\n",
    "for name in basenames[0]:\n",
    "    if not [b for b in basenames[1] if name in b]:\n",
    "        raise ValueError(f\"file {name} does not exist in the raman folder.\")\n",
    "    if not [b for b in basenames[2] if name in b]:\n",
    "        raise ValueError(f\"file {name} does not exist in the photo folder.\")\n",
    "\n",
    "if len(filenames[0]) != len(filenames[1]) or len(filenames[1]) != len(filenames[2]):\n",
    "    raise ValueError(\"The folder do not have the same number of files.\")\n",
    "        \n",
    "\n",
    "with open(f\"{'/'.join(file_locations[0].split('/')[:-2])}/Sample_labels.pickle\", 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "labels = {l.split(\".\")[0]: val for l, val in labels.items()}\n",
    "labels = list(zip(*sorted(labels.items())))[1]\n",
    "\n",
    "wavenumbers = np.load(f\"{file_locations[2]}Wavenumbers.npy\")\n",
    "\n",
    "NORM = False\n",
    "func = unit_vector_norm if NORM else lambda x:x\n",
    "    \n",
    "data = []\n",
    "for filename in filenames:\n",
    "    tmp = []\n",
    "    for f in filename: \n",
    "        x = np.load(f)\n",
    "        tmp.append(func(x.reshape(-1,x.shape[-1])).reshape(x.shape))\n",
    "    data.append(tmp)\n",
    "data.append(labels)\n",
    "\n",
    "data = list(zip(*data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[:1]\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ReLU\n",
    "nn.GELU\n",
    "nn.LeakyReLU\n",
    "nn.ELU\n",
    "\n",
    "\"\"\"\n",
    "Keep sum of weights positive,\n",
    "imag part must be zero (loss function)\n",
    "\"\"\"\n",
    "\n",
    "class SelectLayer(nn.Module):\n",
    "    def __init__(self, layer_index):\n",
    "        super().__init__()\n",
    "        self.layer_index = layer_index\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:,self.layer_index]\n",
    "\n",
    "class Conv_FFT(nn.Module):\n",
    "    def __init__(self, num_input_channels : int = 2, base_channel_size: int = 16, act_fn : object = nn.GELU, groups : int = 2, **kwargs):\n",
    "        super().__init__()\n",
    "        c_hid = base_channel_size\n",
    "        c_hid_2 = base_channel_size //2\n",
    "            \n",
    "        # FFT CNN split\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(num_input_channels, c_hid, kernel_size=11, padding=5, groups=groups, bias=False), \n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid, c_hid, kernel_size=9, padding=4, groups=groups, bias=False),\n",
    "            act_fn(),\n",
    "#             nn.Conv1d(c_hid, c_hid, kernel_size=7, padding=3, groups=groups, bias=False),\n",
    "#             act_fn(),\n",
    "#             nn.Conv1d(c_hid, c_hid, kernel_size=7, padding=3, groups=groups, bias=False),\n",
    "#             act_fn(),\n",
    "            nn.Conv1d(c_hid, c_hid, kernel_size=7, padding=3, groups=groups, bias=False),\n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid, c_hid, kernel_size=7, padding=3, groups=2*groups, bias=False),\n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid, c_hid, kernel_size=5, padding=2, groups=2*groups, bias=False),\n",
    "            act_fn(),\n",
    "#             nn.Conv1d(c_hid, c_hid, kernel_size=5, padding=2, groups=2*groups, bias=False),\n",
    "#             act_fn(),\n",
    "#             nn.Conv1d(c_hid, c_hid, kernel_size=5, padding=2, groups=2*groups, bias=False),\n",
    "#             act_fn(),\n",
    "            nn.Conv1d(c_hid, c_hid, kernel_size=3, padding=1, groups=2*groups, bias=False),\n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid, 2*num_input_channels, kernel_size=3, padding=1, groups=2*groups, bias=False)\n",
    "        )\n",
    "        \n",
    "        # photo smooth part\n",
    "        self.smooth_phase2 = nn.Sequential(\n",
    "            SelectLayer(slice(1,2)),\n",
    "            nn.Conv1d(1, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid_2, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid_2, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "            act_fn(),\n",
    "#             nn.Conv1d(c_hid_2, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "#             act_fn(),\n",
    "#             nn.Conv1d(c_hid_2, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "#             act_fn(),\n",
    "            nn.Conv1d(c_hid_2, 1, kernel_size=3, padding=1, groups=1), \n",
    "            SelectLayer(0)\n",
    "        )\n",
    "        self.smooth_phase1 = nn.Sequential(SelectLayer(1))\n",
    "        \n",
    "        # raman acc part\n",
    "        self.raman_phase3 = nn.Sequential(\n",
    "#             SelectLayer(slice(0,3)),\n",
    "            nn.Conv1d(3, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid_2, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "            act_fn(),\n",
    "#             nn.Conv1d(c_hid_2, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "#             act_fn(),\n",
    "#             nn.Conv1d(c_hid_2, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "#             act_fn(),\n",
    "            nn.Conv1d(c_hid_2, c_hid_2, kernel_size=5, padding=2, groups=1, bias=False), \n",
    "            act_fn(),\n",
    "            nn.Conv1d(c_hid_2, 1, kernel_size=3, padding=1, groups=1), \n",
    "            SelectLayer(0)\n",
    "        )\n",
    "        self.raman_phase1 = nn.Sequential(SelectLayer(2))\n",
    "        \n",
    "        self.set_training(0)\n",
    "        \n",
    "    def set_training(self, value):\n",
    "        if value == 0:\n",
    "            self.smooth = self.smooth_phase1\n",
    "            self.raman = self.raman_phase1\n",
    "        elif value == 1:\n",
    "            self.smooth = self.smooth_phase2\n",
    "            self.raman = self.raman_phase1\n",
    "        elif value == 2:\n",
    "            self.smooth = self.smooth_phase2\n",
    "            self.raman = self.raman_phase3\n",
    "            \n",
    "    def forward(self, x):\n",
    "        n_wavenumbers = x.shape[-1]\n",
    "        d = 1\n",
    "        x0 = torch.fft.rfft(x, dim=d, norm='backward')\n",
    "        x0 = torch.stack((x0.real, x0.imag), 1)\n",
    "        x0 = self.net(x0)\n",
    "        x1, x2 = x0[:,[0,2]], x0[:,[1,3]]\n",
    "        x1, x2 = torch.transpose(x1, -2, -1).contiguous(), torch.transpose(x2, -2, -1).contiguous()\n",
    "        x1, x2 = torch.view_as_complex(x1), torch.view_as_complex(x2)\n",
    "        x1, x2 = torch.fft.irfft(x1, n=n_wavenumbers, dim=d, norm='backward'), torch.fft.irfft(x2, n=n_wavenumbers, dim=d, norm='backward')\n",
    "        x3 = torch.stack((x, x1, x2),1)\n",
    "        return self.smooth(x3), self.raman(x3), x1, x2\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         n_wavenumbers = x.shape[-1]\n",
    "#         d = 1\n",
    "#         x = torch.fft.fft(x, dim=d, norm='backward')\n",
    "#         x = torch.stack((x.real, x.imag), 1)\n",
    "#         x = self.net(x)\n",
    "#         x1, x2 = x[:,[0,2]], x[:,[1,3]]\n",
    "#         x1, x2 = torch.transpose(x1, -2, -1).contiguous(), torch.transpose(x2, -2, -1).contiguous()\n",
    "#         x1, x2 = torch.view_as_complex(x1), torch.view_as_complex(x2)\n",
    "#         x1, x2 = torch.fft.ifft(x1, dim=d, norm='backward').real, torch.fft.ifft(x2, dim=d, norm='backward').real\n",
    "#         if self.pretraining:\n",
    "#             return x1, x2\n",
    "#         return self.smooth(x1.reshape(-1, 1, n_wavenumbers)).reshape(x.shape[0],-1), x2\n",
    "\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Normal CNN\n",
    "#         \"\"\"\n",
    "#         x0 = x.reshape(-1, 1, x.shape[-1])\n",
    "#         x0 = self.net(x0)\n",
    "#         x1, x2 = x0[:,0].reshape(x.shape), x0[:,1].reshape(x.shape)\n",
    "#         x3 = torch.stack((x, x1, x2),1)\n",
    "#         return self.smooth(x3).reshape(x.shape[0],-1), self.raman(x3).reshape(x.shape[0],-1), x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedClassifier(BaseEstimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        _use_cuda = torch.cuda.is_available() and kwargs['cuda']\n",
    "        if _use_cuda:\n",
    "            torch.backends.cudnn.enabled = True\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        self.device = torch.device('cuda' if _use_cuda else 'cpu')        \n",
    "        print(f\"device: {self.device}\")\n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.model = Conv_FFT().to(self.device)\n",
    "\n",
    "        parameters = filter(lambda x: x.requires_grad, self.model.parameters())\n",
    "        self.optimizer = optim.Adam(parameters, lr=self.kwargs['lr'])                \n",
    "        self.train_loader, self.test_loader = dataset.load_splitdata(data, self.kwargs['batch_size'])\n",
    "            \n",
    "        for epoch in range(self.kwargs['epochs']):\n",
    "            if os.path.exists(f\"{saved_NN}//Conv_FFT_model_epoch{epoch}.pt\"):\n",
    "                print(f\"epoch {epoch} is already trained\")\n",
    "                if not os.path.exists(f\"{saved_NN}//Conv_FFT_model_epoch{epoch+1}.pt\"):\n",
    "                    self.model = torch.load(f\"{saved_NN}//Conv_FFT_model_epoch{epoch}.pt\", map_location=self.device) \n",
    "                    parameters = filter(lambda x: x.requires_grad, self.model.parameters())\n",
    "                    self.optimizer = optim.Adam(parameters, lr=self.kwargs['lr'])  \n",
    "                continue \n",
    "                \n",
    "            if epoch >= 30:\n",
    "                self.model.set_training(1)\n",
    "            if epoch >= 33:\n",
    "                self.model.set_training(2)\n",
    "                \n",
    "            print('-'*50)\n",
    "            print('Epoch {:3d}/{:3d}'.format(epoch, self.kwargs['epochs']))\n",
    "            start_time = datetime.now()\n",
    "            train.train(self.model, self.optimizer, self.train_loader, self.kwargs['loss_func'], self.kwargs['acc_func'], self.kwargs['log_step'], self.device)\n",
    "            end_time = datetime.now()\n",
    "            time_diff = relativedelta(end_time, start_time)\n",
    "            print('Elapsed time: {}h {}m {}s'.format(time_diff.hours, time_diff.minutes, time_diff.seconds))\n",
    "            train.test(self.model, self.test_loader, self.kwargs['loss_func'], self.kwargs['acc_func'], self.kwargs['log_step'], self.device)\n",
    "            torch.save(self.model, f\"{saved_NN}//Conv_FFT_model_epoch{epoch}.pt\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if data is not None:\n",
    "            _, dataloader = dataset.load_splitdata(data, self.kwargs['batch_size'], test_size=None)\n",
    "            for batch_idx, (x, *y) in enumerate(dataloader):\n",
    "                x = x.to(self.device)\n",
    "                y_1, y_2, y_3, y_4 = self.model(x)\n",
    "                y1, y2, *_ = y\n",
    "                yield x.cpu().detach().numpy(), y1, y2, y_1.cpu().detach().numpy(), y_2.cpu().detach().numpy(), y_3.cpu().detach().numpy(), y_4.cpu().detach().numpy()\n",
    "        else:\n",
    "            for batch_idx, (x, *y) in enumerate(self.test_loader):\n",
    "                x = x.to(self.device)\n",
    "                y_1, y_2, *_ = self.model(x)\n",
    "                y1, y2, *_ = y\n",
    "                yield x.cpu().detach().numpy(), y1, y2, y_1.cpu().detach().numpy(), y_2.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6509fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "loss2 = nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n",
    "# loss3 = nn.KLDivLoss(size_average=None, reduce=None, reduction='batchmean', log_target=False)\n",
    "# both closely related\n",
    "# loss4 = nn.HuberLoss(reduction='mean', delta=100.0)\n",
    "# loss5 = nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean', beta=1.0)\n",
    "\n",
    "def loss_func(y, y_, x):\n",
    "    raman, photo, _ = y\n",
    "    raman = raman.to(y_[0].device)\n",
    "    photo = photo.to(y_[0].device)\n",
    "    return loss1(y_[0], photo) + loss1(y_[1], raman)\n",
    "\n",
    "def acc_func(y, y_, x, data=\"train\"):\n",
    "    y_1, y_2, y_3, y_4 = y_\n",
    "    y_1, y_2, y_3, y_4 = y_1.cpu().detach().numpy(), y_2.cpu().detach().numpy(), y_3.cpu().detach().numpy(), y_4.cpu().detach().numpy()\n",
    "    x = x.cpu().detach().numpy()\n",
    "    plt.title(f\"plot {data} data\")\n",
    "    plt.plot(x[0], label='raw')\n",
    "    plt.plot(y_1[0] + y_2[0], label='raman+photo')\n",
    "    plt.plot(np.abs(x[0]-y_1[0]-y_2[0]), label='noise', color='orange')\n",
    "    plt.plot(y[0][0], label='raman', color='c')\n",
    "    plt.plot(y[1][0], label='photo', color='r')\n",
    "    plt.plot(y_1[0], label='Conv1/photo', color='g')\n",
    "    plt.plot(y_2[0], label='Conv2/raman', color='brown')\n",
    "    plt.plot(y_3[0], label='Conv/pre_photo', color='b')\n",
    "    plt.plot(y_4[0], label='Conv/pre_raman', color='r')\n",
    "    plt.ylim(ymin=-10)\n",
    "    plt.xlim(xmin=0, xmax=1300)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return loss_func(y, y_, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "kwargs = {'batch_size': BATCH_SIZE,\n",
    "          'cuda': True,\n",
    "          'log_step': 5000,\n",
    "          'epochs': EPOCHS,\n",
    "          'loss_func': loss_func,\n",
    "          'acc_func' : acc_func,\n",
    "          'bias': True,\n",
    "          'lr': 0.001\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703feef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rvc = SupervisedClassifier(**kwargs)\n",
    "rvc.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61251d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = 0\n",
    "for parameter in rvc.model.parameters():\n",
    "    print(np.prod(parameter.shape), parameter.shape)\n",
    "    s += np.prod(parameter.shape)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54368d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DESKTOP\n",
    "# file_locations = [\"../data/Raman_Mouse/preprocessed_2022-11-30 11-48-26.672496/\",\n",
    "#                   \"../data/Raman_Mouse/raman_2022-11-30 12-16-11.285597/\",\n",
    "#                   \"../data/Raman_Mouse/photoluminences_2022-11-30 12-16-25.050493/\"]\n",
    "# # LAPTOP\n",
    "# # file_locations = [\"../data/Raman_Mouse/preprocessed_2022-12-01 11-53-44.127304/\",\n",
    "# #                   \"../data/Raman_Mouse/raman_2022-12-01 12-13-34.452351/\",\n",
    "# #                   \"../data/Raman_Mouse/photoluminences_2022-12-01 12-13-35.526177/\"]\n",
    "# # filenames = [sorted(glob.glob(file_location+'/[!Wave|!Liver|!Kidney]*.npy')) for file_location in file_locations]\n",
    "# filenames = [sorted(glob.glob(file_location+'/[!Wave|!muscle]*.npy')) for file_location in file_locations]\n",
    "# # filenames = [sorted(glob.glob(file_location+'/[!Wave]*.npy')) for file_location in file_locations]\n",
    "\n",
    "# saved_NN = \"saved_NN\"\n",
    "# os.makedirs(saved_NN, exist_ok=True)\n",
    "\n",
    "# basenames = [[os.path.splitext(os.path.basename(f))[0] for f in filename] for filename in filenames]\n",
    "\n",
    "# # check if all files exist\n",
    "# for name in basenames[0]:\n",
    "#     if not [b for b in basenames[1] if name in b]:\n",
    "#         raise ValueError(f\"file {name} does not exist in the raman folder.\")\n",
    "#     if not [b for b in basenames[2] if name in b]:\n",
    "#         raise ValueError(f\"file {name} does not exist in the photo folder.\")\n",
    "\n",
    "# if len(filenames[0]) != len(filenames[1]) or len(filenames[1]) != len(filenames[2]):\n",
    "#     raise ValueError(\"The folder do not have the same number of files.\")\n",
    "        \n",
    "\n",
    "# with open(f\"{'/'.join(file_locations[0].split('/')[:-2])}/Sample_labels.pickle\", 'rb') as f:\n",
    "#     labels = pickle.load(f)\n",
    "# labels = {l.split(\".\")[0]: val for l, val in labels.items()}\n",
    "# labels = list(zip(*sorted(labels.items())))[1]\n",
    "\n",
    "# wavenumbers = np.load(f\"{file_locations[2]}Wavenumbers.npy\")\n",
    "\n",
    "# NORM = False\n",
    "# func = unit_vector_norm if NORM else lambda x:x\n",
    "    \n",
    "# data = []\n",
    "# for filename in filenames:\n",
    "#     tmp = []\n",
    "#     for f in filename: \n",
    "#         x = np.load(f)\n",
    "#         tmp.append(func(x.reshape(-1,x.shape[-1])).reshape(x.shape))\n",
    "#     data.append(tmp)\n",
    "# data.append(labels)\n",
    "\n",
    "# data = list(zip(*data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4644f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, (x, y1, y2, y_1, y_2, y_3, y_4) in enumerate(rvc.predict(data)):\n",
    "#     if not i % (3750 // 64):\n",
    "#         indices = np.random.choice(BATCH_SIZE, 1, replace=False)\n",
    "#         for i in indices:\n",
    "#             plt.plot(x[i], label='raw')\n",
    "#             plt.plot(y_1[i] + y_2[i], label='raman+photo')\n",
    "#             plt.plot(y1[i], label='raman')\n",
    "#             plt.plot(y2[i], label='photo')\n",
    "#             plt.plot(y_1[i], label='Conv1/photo')\n",
    "#             plt.plot(y_2[i], label='Conv2/raman')\n",
    "# #             plt.plot(y_3[i], label='Conv2/pre photo')\n",
    "# #             plt.plot(y_4[i], label='Conv2/pre raman')            \n",
    "#             plt.plot(np.abs(x[i]-y_1[i]-y_2[i]), label='noise')\n",
    "#             plt.ylim(ymin=-10)\n",
    "#             plt.xlim(xmin=0, xmax=1300)\n",
    "#             plt.legend()\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abda99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
