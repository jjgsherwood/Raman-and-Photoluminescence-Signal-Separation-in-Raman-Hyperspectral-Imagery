{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1881fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from scipy import ndimage\n",
    "from BaselineRemoval import BaselineRemoval\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, ifft, fftfreq, dct\n",
    "from sklearn.decomposition import PCA\n",
    "import timeit\n",
    "from os import path\n",
    "\n",
    "from signal_processing import smoothing, splitting, LSQ, error\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a47ad",
   "metadata": {},
   "source": [
    "Mogelijke verbeteringen:\n",
    " - maak de covariance afhankelijke van de noise \n",
    " - draai de spectrum zodanig dat de globale sloop de x-as is. Zodat het min-max algorithme beter werkt. DONE\n",
    " - de smoothing die applied wordt door de covariantie moet afgesteld worden per sample\n",
    "\n",
    "Problemen:\n",
    " - initializatie maakt uit voor de kalman smoother (hoeveel noise er is vs raman)\n",
    " - aantal iteratie maakt uit voor de kalman smoother (hoeveel noise er is vs raman)\n",
    " - de bounderies hebben geen invloed op de kalman smoother buiten alles binnen de bounderies houden.\n",
    "   Tenzij smoothing ook aanstaat.\n",
    "   \n",
    "   \n",
    "excitation laser maakt uit hoe de raman laser eruit ziet. Hoger (rood) betekend lower raman signal en een breder signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1a83d",
   "metadata": {},
   "source": [
    "date: 2-9-2022\n",
    "\n",
    " - stabilise the logic part with neighbourhood information\n",
    " - where the logic part is true make the line segments bigger (does not work)\n",
    " - find something to deterime the smoothness of the poly fit (no bumbs) DONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73996df5",
   "metadata": {},
   "source": [
    "# important facts\n",
    "\n",
    "#### dirac delta gives an cosine in the fourier space where the period is equal to 2N/(n+0.5)\n",
    "#### FWHM to freq index is: k = 2 * (w[-1] - w[0]) / (3 * FWHM)\n",
    "#### gaussian is gaussian/2 in cosine transform space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f0431",
   "metadata": {},
   "source": [
    "### Ideas:\n",
    "\n",
    "- Wavelet transform (for NN to big as an input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec150d8",
   "metadata": {},
   "source": [
    "### Errors:\n",
    "\n",
    " - smooth_grad fix the try except clause such that and the beginning and end of the spectrum it also works\n",
    " - using fourier transform it seems that gibbs phenomena is a problem (spectral leakage). Also a dirac function becomes a cosine/sine wave in the fourier space. After a LPB this looks like gibbs phenomena aswell, closely related\n",
    " - in the raman spectra nan values are returned for the UnivariateSpline method when approimating the imaginary part of the fft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2f1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"../data/Raman_Mouse/preprocessed/\"\n",
    "# file_location = \"../data/Green_excitation/corrected_4_wavenumbers/\"\n",
    "\n",
    "filenames = glob.glob(file_location+'/[!Wave|File]*.npy')\n",
    "with open(f\"{'/'.join(file_location.split('/')[:-2])}/Sample_labels.pickle\", 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "labels = {l.split(\".\")[0]: val for l, val in labels.items()}\n",
    "\n",
    "wavenumbers = np.load(f\"{file_location}Wavenumbers.npy\")\n",
    "    \n",
    "def unit_vector_norm(X):\n",
    "    return (X.T / np.sqrt((X**2).sum(axis=1))).T\n",
    "    \n",
    "NORM = False\n",
    "func = unit_vector_norm if NORM else lambda x:x\n",
    "    \n",
    "data = []\n",
    "for f in filenames:\n",
    "    x = np.load(f)\n",
    "    data.append((func(x.reshape(-1,x.shape[-1])).reshape(x.shape),))\n",
    "#     break\n",
    "    \n",
    "# #mouse image\n",
    "# noise_amount = 1e5\n",
    "# intervals = 10\n",
    "# general_noise = 10e6\n",
    "# poly_fit = 1e5\n",
    "# precision = 12\n",
    "# continue_gap = 100\n",
    "# # green image\n",
    "# noise_amount = 3e5\n",
    "# general_noise = 5e6\n",
    "# intervals = 30\n",
    "# precision = 20\n",
    "# poly_fit = 8e5\n",
    "# continue_gap = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab52ec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSmoothing code to show what happens with large spike in the DCT space.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Smoothing code to show what happens with large spike in the DCT space.\n",
    "\"\"\"\n",
    "# def __LPF_auto__(self, x):\n",
    "#     # find spike that are to similar to a dirac delta function\n",
    "#     i = 0\n",
    "#     w = self.gradient_width\n",
    "#     # x[i] = ndimage.uniform_filter1d(x[i], 3)\n",
    "#     grad = np.abs(x[:,w:] - x[:,:-w])\n",
    "#     std_grad = np.std(grad, 1)\n",
    "#     plt.plot(grad[i])\n",
    "#     print(std_grad[i])\n",
    "#     plt.axhline(3*std_grad[i])\n",
    "#     plt.show()\n",
    "#     print(self.max_spike_width)\n",
    "#     position, details = signal.find_peaks(x[i], rel_height=.7, prominence=std_grad[i]*3, width=(None,self.max_spike_width))\n",
    "#\n",
    "#     print(details)\n",
    "#     spike = np.zeros(x.shape)\n",
    "#     for j,p in enumerate(position):\n",
    "#         half_w = int(details['widths'][j]//2+self.spike_padding)\n",
    "#         left, right = max(0, p-half_w), min(p+half_w, x.shape[1]-1)\n",
    "#         base = np.linspace(x[i,left], x[i,right], right-left+1)\n",
    "#         spike[i,left:right+1] = x[i,left:right+1] - base\n",
    "#         plt.axvline(p)\n",
    "#\n",
    "#     plt.plot(x[i], linewidth=2)\n",
    "#     plt.plot(spike[i], alpha=0.6, linewidth=1)\n",
    "#     plt.plot(x[i]-spike[i], linewidth=0.3, color='r')\n",
    "#\n",
    "#     cosine = dct(x-spike, type=2, norm='backward')\n",
    "#     cosine = cosine.T\n",
    "#     cosine[self.k:] = np.mean(cosine[self.k:], 0)\n",
    "#\n",
    "#     tmp = dct(cosine.T, type=3, norm=\"forward\")+spike\n",
    "#     # plt.plot(tmp[i])\n",
    "#     plt.show()\n",
    "#\n",
    "#     plt.plot(cosine[:,i])\n",
    "#     cosine = dct(x, type=2, norm='backward')\n",
    "#     plt.plot(cosine[i], alpha=0.3)\n",
    "#     cosine = dct(spike, type=2, norm='backward')\n",
    "#     plt.plot(cosine[i])\n",
    "#     plt.show()\n",
    "#\n",
    "#     return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44caef30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IDEA BEZIER_curve Trough 3 points can be achieved by two bezier curves where two anchor points are calculate between L and M and M and R. \n",
    "This can be done by calculating the gradient between L and R and multiply the gradient by half the distance between L and M plus M. (same for R)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def Bezier_curve(p0,p1,p2):\n",
    "    x0, x1, x2 = p0[0], p1[0], p2[0]\n",
    "    b, a = x0 - x1, x0 - 2*x1 + x2\n",
    "    d = x1**2 - x0*x2\n",
    "    def inv_B(x):\n",
    "        if not a:\n",
    "            return np.linspace(0,1,x.shape[-1])\n",
    "        return (b + np.sqrt(d + a * x)) / a\n",
    "    \n",
    "    p0, p1, p2 = p0[1], p1[1], p2[1]\n",
    "    p1 = 0\n",
    "    def B(t):\n",
    "        return (1-t)**2 * p0 + 2*(1-t)*t * p1 + t**2 * p2 \n",
    "    \n",
    "    return B, inv_B\n",
    "\n",
    "def fit_gradient_line_segment(x, grad, middle, width):\n",
    "    \"\"\"\n",
    "    LSQ seems to work better, but bezier curve is faster.\n",
    "    Let the user decide\n",
    "    \n",
    "    \"\"\"\n",
    "    left, right = np.maximum(0, middle-width), np.minimum(x.shape[-1]-1, middle+width)\n",
    "    middle = np.minimum(x.shape[0]-1,np.maximum(middle, 0))\n",
    "    width = right-left\n",
    "    if left == middle:\n",
    "        middle += 1\n",
    "    elif right == middle:\n",
    "        middle -= 1\n",
    "    \n",
    "    grad_left = grad[left]\n",
    "    grad_middle = grad[middle]\n",
    "    grad_right = grad[right]\n",
    "#     left_grad = np.linspace(grad_left, grad_middle, middle-left)\n",
    "#     right_grad = np.linspace(grad_middle, grad_right, right-middle)\n",
    "#     grad = np.concatenate((left_grad, right_grad))\n",
    "\n",
    "    axis = np.arange(left, right)\n",
    "    order = np.arange(3)\n",
    "    kernel = axis[:, np.newaxis]**order\n",
    "    p, *_ = np.linalg.lstsq(kernel, grad[left: right], rcond=None)\n",
    "    grad = np.sum(kernel * p, 1)\n",
    "\n",
    "#     p0 = np.array([left, grad_left])\n",
    "#     p1 = np.array([middle, grad_middle])\n",
    "#     p2 = np.array([right, grad_right])\n",
    "    \n",
    "#     B, inv_B = Bezier_curve(p0, p1, p2)\n",
    "#     x_axis = np.arange(left, right+1)\n",
    "#     grad = B(inv_B(x_axis))[:-1]\n",
    "       \n",
    "    value = 0\n",
    "    slope = [0]\n",
    "    for g in grad:\n",
    "        value += g\n",
    "        slope.append(value)\n",
    "\n",
    "    slope = np.array(slope)\n",
    "    index = np.argmin(x[left:right+1] - slope)\n",
    "    slope -= slope[index]\n",
    "\n",
    "    slope += x[left+index]\n",
    "#     plt.plot(x_axis, slope)\n",
    "    return slope, left, right+1\n",
    "\n",
    "def init_poly_approximation(continue_gap=400, intervals=50, size=1300):\n",
    "    photo_approximation = LSQ.photo_approximation(wavenumbers, order=9, FWHM=3000, size=size)\n",
    "    def poly_approximation(x, approximation):\n",
    "        step = x.shape[0]//intervals\n",
    "        grad =  np.pad((approximation[2:] - approximation[:-2]) / 2, (1,1), 'edge')\n",
    "        grad[0] -= grad[2] - grad[1]\n",
    "        grad[-1] += grad[-2] - grad[-3]\n",
    "               \n",
    "        start = timeit.default_timer()\n",
    "        \n",
    "        lst = []\n",
    "        widths = [250] # original\n",
    "#         widths = [400] # green\n",
    "        for j in widths:\n",
    "            poly_max = np.zeros(x.shape[-1])\n",
    "#             plt.plot(grad, 'k', alpha=0.5)\n",
    "#             plt.plot(x, 'k', alpha=0.5)\n",
    "            for i in range(-j+11, x.shape[-1]+j-10, step):\n",
    "                tmp, left, right = fit_gradient_line_segment(x, grad, i, j)\n",
    "                poly_max[left:right] = np.maximum(poly_max[left:right], tmp)\n",
    "#             plt.show()\n",
    "            lst.append(poly_max)\n",
    "        poly = np.min(np.array(lst), 0)\n",
    "                        \n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "        print('Time inner 1: ', stop - start)  \n",
    "        \n",
    " \n",
    "\n",
    "        start = timeit.default_timer()\n",
    "    \n",
    "        weights = np.ones(x.shape[0])\n",
    "#         plt.plot(x)\n",
    "#         plt.plot(poly)\n",
    "        old = -1\n",
    "        poly2 = poly\n",
    "        poly2[poly2 <= 0] = 1e-8\n",
    "        while (new_old := error.MAPE(poly, poly2)) - old > 1e-4:\n",
    "            old = new_old\n",
    "#             plt.plot(poly)\n",
    "            poly2 = photo_approximation(poly, np.diag(weights))\n",
    "            to_high = poly2 > x\n",
    "            weights[to_high] += 0.5\n",
    "            weights /= np.mean(weights)\n",
    "            poly[to_high] *= 0.9875\n",
    "            poly[poly <= 0] = 1e-8\n",
    "            poly2[poly2 <= 0] = 1e-8\n",
    "#             plt.plot(poly2)\n",
    "#         plt.show()\n",
    "    \n",
    "        stop = timeit.default_timer()\n",
    "        print('Time inner 2: ', stop - start)  \n",
    "    \n",
    "        return poly2\n",
    "    return poly_approximation\n",
    "poly_approximation = init_poly_approximation(size=data[0][0].shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab505aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "log-scale fitting works better, why?\n",
    "\n",
    "preliminary_photo_approximation1  the polynomial fit order can be determined with the MAPE (if it stops increasing)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# remove_noise_cube_fft = smoothing.RemoveNoiseFFTPCA(algorithm='LPF', percentage_noise=None, wavenumbers=wavenumbers, min_FWHM=5, gradient_width=10, spike_padding=10, max_spike_width=100, Print=False)\n",
    "remove_noise_cube_fft = smoothing.RemoveNoiseFFTPCA(algorithm='PCA', percentage_noise=None, wavenumbers=wavenumbers, min_FWHM=5, gradient_width=50, spike_padding=0, max_spike_width=100, Print=False)\n",
    "preliminary_photo_approximation = splitting.preliminary_split(wavenumbers, order=1, FWHM=2000, size=data[0][0].shape[-1])\n",
    "photo_approximation = splitting.split(wavenumbers, intervals=50, order=1, FWHM=2000, size=data[0][0].shape[-1])\n",
    "\n",
    "def split_signal(img):\n",
    "    \"\"\" \n",
    "    img consists of data and label\n",
    "    \n",
    "    artefact due to using previous points \n",
    "    \n",
    "    \"\"\"   \n",
    "    x = img[0].reshape(-1, img[0].shape[-1])    \n",
    "    org = copy.copy(x)\n",
    "        \n",
    "    raman = np.empty(x.shape)\n",
    "    photo = np.empty(x.shape)\n",
    "    start = timeit.default_timer()\n",
    "        \n",
    "    # check for cube\n",
    "    if np.prod(img[0].shape) != img[0].shape[-1]:\n",
    "        x = remove_noise_cube_fft(x)\n",
    "                \n",
    "    \"\"\"\n",
    "    This is done, photo_approximation needs tweaking\n",
    "    \"\"\"\n",
    "    start = timeit.default_timer()\n",
    "    poly = preliminary_photo_approximation(x)       \n",
    "    stop = timeit.default_timer()\n",
    "    print('Time 1: ', stop - start)\n",
    "    \n",
    "    photo = photo_approximation(poly, x)\n",
    "    print(photo.shape)\n",
    "    return\n",
    "    \n",
    "    for pixel in range(x.shape[0]):\n",
    "        pixel = 85\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        poly2 = poly_approximation(x[pixel], poly[pixel])\n",
    "        for i in range(3):\n",
    "            poly2 = poly_approximation(x[pixel], poly2)\n",
    "        stop = timeit.default_timer()\n",
    "        print('Time 2: ', stop - start) \n",
    "        \n",
    "        plt.plot(org[pixel], label=\"org\")\n",
    "        plt.plot(poly[pixel], label=\"approximation\")\n",
    "        plt.plot(poly2, label=\"photo\")\n",
    "        plt.plot(x[pixel] - poly2, label=\"raman\")\n",
    "        plt.plot(x[pixel], label=\"smooth\")\n",
    "        plt.plot(org[pixel] - x[pixel], label=\"noise\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        return\n",
    "        raman2 = x[pixel] - poly2\n",
    "        \n",
    "        # raman approximation'\n",
    "#         plt.plot(remove_noise_fft(x[pixel]-poly2))\n",
    "#         plt.show()\n",
    "                \n",
    "        raman[pixel] = raman2\n",
    "        photo[pixel] = poly2\n",
    "        if not pixel % 100:\n",
    "            stop = timeit.default_timer()\n",
    "            print(f\"progress = {100* pixel / x.shape[0]}%, 100 samples time : {stop - start}\")\n",
    "            start = timeit.default_timer()\n",
    "        \n",
    "    return raman, photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53174a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Raman_Mouse/preprocessed/Liver_map_150z25_60s_#14.npy\n",
      "Time 1:  0.1613870430010138\n",
      "[9.51764608 9.36901941 9.22039274 ... 0.         0.         0.        ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-151742f3afd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print(f'file already exist {file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msplit_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#     raman, photo = split_signal(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-832645a6359e>\u001b[0m in \u001b[0;36msplit_signal\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time 1: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mphoto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphoto_approximation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Master_thesis/signal_processing/splitting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img, photo)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_gradient_line_segment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mpoly_max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "file_location2 = f\"{'/'.join(file_location.split('/')[:-2])}/approximated_curve_fit/\"\n",
    "os.makedirs(file_location2, exist_ok=True)\n",
    "\n",
    "shape = data[0][0].shape\n",
    "\n",
    "for j, (f, img) in enumerate(zip(filenames, data)):   \n",
    "    start = timeit.default_timer()\n",
    "#     if f != 'Liver_map_150z25_60s_#6.npy':\n",
    "#         continue\n",
    "#     if j < 32:\n",
    "#         continue\n",
    "    \n",
    "    print(f)\n",
    "#     if path.exists(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman.npy'):\n",
    "#         print(f'file already exist {file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman')\n",
    "#         continue\n",
    "    split_signal(img)\n",
    "#     raman, photo = split_signal(img)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', stop - start)  \n",
    "#     break\n",
    "\n",
    "#     np.save(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman', raman.reshape(shape))\n",
    "#     np.save(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_photoluminescence', photo.reshape(shape))\n",
    "#     print(f\"image: {f} is done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea49cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97049031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17f305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c90cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c4f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d1276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
