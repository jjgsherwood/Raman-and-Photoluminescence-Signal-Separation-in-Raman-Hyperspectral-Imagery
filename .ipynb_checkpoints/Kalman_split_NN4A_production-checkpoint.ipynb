{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1881fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from scipy import ndimage\n",
    "from BaselineRemoval import BaselineRemoval\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from sklearn.decomposition import PCA\n",
    "import timeit\n",
    "from os import path\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a47ad",
   "metadata": {},
   "source": [
    "Mogelijke verbeteringen:\n",
    " - maak de covariance afhankelijke van de noise \n",
    " - draai de spectrum zodanig dat de globale sloop de x-as is. Zodat het min-max algorithme beter werkt. DONE\n",
    " - de smoothing die applied wordt door de covariantie moet afgesteld worden per sample\n",
    "\n",
    "Problemen:\n",
    " - initializatie maakt uit voor de kalman smoother (hoeveel noise er is vs raman)\n",
    " - aantal iteratie maakt uit voor de kalman smoother (hoeveel noise er is vs raman)\n",
    " - de bounderies hebben geen invloed op de kalman smoother buiten alles binnen de bounderies houden.\n",
    "   Tenzij smoothing ook aanstaat.\n",
    "   \n",
    "   \n",
    "excitation laser maakt uit hoe de raman laser eruit ziet. Hoger (rood) betekend lower raman signal en een breder signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1a83d",
   "metadata": {},
   "source": [
    "date: 2-9-2022\n",
    "\n",
    " - stabilise the logic part with neighbourhood information\n",
    " - where the logic part is true make the line segments bigger (does not work)\n",
    " - find something to deterime the smoothness of the poly fit (no bumbs) DONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f0431",
   "metadata": {},
   "source": [
    "### Ideas:\n",
    "\n",
    "- Wavelet transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec150d8",
   "metadata": {},
   "source": [
    "### Errors:\n",
    "\n",
    " - smooth_grad fix the try except clause such that and the beginning and end of the spectrum it also works\n",
    " - using fourier transform it seems that gibbs phenomena is a problem\n",
    " - in the raman spectra nan values are returned for the UnivariateSpline method when approimating the imaginary part of the fft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2f1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"../data/Raman_Mouse/corrected_4_wavenumbers/\"\n",
    "# file_location = \"../data/Green_excitation/corrected_4_wavenumbers/\"\n",
    "\n",
    "filenames = np.load(f\"{file_location}FileNames.npy\")\n",
    "with open(f\"{'/'.join(file_location.split('/')[:-2])}/Sample_labels.pickle\", 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "labels = {l.split(\".\")[0]: val for l, val in labels.items()}\n",
    "\n",
    "wavenumbers = np.load(f\"{file_location}Wavenumbers.npy\")\n",
    "    \n",
    "data = []\n",
    "for f in filenames:\n",
    "    x = np.load(f\"{file_location}{f.split('.')[0]}.npy\")\n",
    "    data.append(((x.reshape(-1,x.shape[-1])).reshape(x.shape), labels[f.split(\".\")[0]]))\n",
    "    \n",
    "# #mouse image\n",
    "# noise_amount = 1e5\n",
    "# intervals = 10\n",
    "# general_noise = 10e6\n",
    "# poly_fit = 1e5\n",
    "# precision = 12\n",
    "# continue_gap = 100\n",
    "# # green image\n",
    "# noise_amount = 3e5\n",
    "# general_noise = 5e6\n",
    "# intervals = 30\n",
    "# precision = 20\n",
    "# poly_fit = 8e5\n",
    "# continue_gap = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b11600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise_fft_min(min_HWHM=5, spline_appr=5e9):\n",
    "    k = int((wavenumbers[-1] - wavenumbers[0]) / (2*min_HWHM))\n",
    "    def remove_noise_fft(x):       \n",
    "        x_ = copy.copy(x)\n",
    "        mean = np.mean(x)\n",
    "        x_ -= mean\n",
    "        fourier = fft(x_)\n",
    "\n",
    "        fourier_real = fourier.real\n",
    "        fourier_imag = fourier.imag\n",
    "        \n",
    "        space = np.arange(x.shape[0])\n",
    "        \n",
    "        func = interpolate.UnivariateSpline(space, fourier_real, k=4, s=spline_appr)\n",
    "        fourier_real[k:-k] = func(space[k:-k])\n",
    "        if sum(np.isnan(fourier_real[k:-k])):\n",
    "            fourier_real[k:-k] = 0\n",
    "        \n",
    "        func = interpolate.UnivariateSpline(space, fourier_imag, k=4, s=spline_appr)\n",
    "        fourier_imag[k:-k] = func(space[k:-k])\n",
    "        if sum(np.isnan(fourier_imag[k:-k])):\n",
    "            fourier_imag[k:-k] = 0\n",
    "        \n",
    "        smooth_fourier = fourier_real + 1j * fourier_imag\n",
    "\n",
    "        return ifft(smooth_fourier) + mean\n",
    "    return remove_noise_fft\n",
    "remove_noise_fft = remove_noise_fft_min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f644fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma, scale):\n",
    "    x = scale * np.exp(-0.5* ((x - mu) / sigma)**2)\n",
    "    return x * (x > min(scale/10, 10))\n",
    "\n",
    "def init_fit_gaussian(min_wavenumber=-1000, left_steps=10, min_sigma=100, max_sigma=1500, steps=20):\n",
    "    def fit_gaussian(x):\n",
    "        lst = []\n",
    "        for mu in np.concatenate((np.linspace(-min_wavenumber, 0, left_steps), np.linspace(wavenumbers[0], wavenumbers[-1], steps))):\n",
    "            temp_mu = 0,1,1\n",
    "            temp_intergral = 0\n",
    "            for sigma in np.linspace(min_sigma**0.5, max_sigma**0.5, steps)**2:\n",
    "                if mu < 0 and mu + 3*sigma < 0:\n",
    "                    continue\n",
    "\n",
    "                scale = 10\n",
    "                current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "\n",
    "                for delta in 10**np.arange(10, -1, -1):\n",
    "                    while not np.sum((current - x) > 0):\n",
    "                        scale += delta\n",
    "                        current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "                    else:\n",
    "                        scale -= delta\n",
    "                        current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "\n",
    "                intergral = np.sum(current)\n",
    "                if intergral > temp_intergral:\n",
    "                    temp_intergral = intergral\n",
    "                    temp_mu = mu, sigma, scale\n",
    "\n",
    "            if temp_mu[1] < min_sigma: #no fit found\n",
    "                continue\n",
    "\n",
    "            for sigma in np.linspace(max(min_sigma, temp_mu[1]-50), temp_mu[1]+50, steps):\n",
    "                if mu < 0 and mu + 3*sigma < 0:\n",
    "                    continue\n",
    "                scale = 10\n",
    "                current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "\n",
    "                for delta in 10**np.arange(10, -1, -1):\n",
    "                    while not np.sum((current - x) > 0):\n",
    "                        scale += delta\n",
    "                        current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "                    else:\n",
    "                        scale -= delta\n",
    "                        current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "\n",
    "                intergral = np.sum(current)\n",
    "                if intergral > temp_intergral:\n",
    "                    temp_intergral = intergral\n",
    "                    temp_mu = mu, sigma, scale\n",
    "\n",
    "            lst.append(gaussian(wavenumbers, *temp_mu))\n",
    "        lst = np.array(lst)\n",
    "        return np.max(lst, axis=0)\n",
    "    return fit_gaussian\n",
    "    \n",
    "def preliminary_photo_approximation(x):\n",
    "    fit_gaussian = init_fit_gaussian()\n",
    "    fit_gaussian2 = init_fit_gaussian(left_steps=0)\n",
    "    \n",
    "    x_ = copy.copy(x)\n",
    "    gaussians = []   \n",
    "    for fit in [fit_gaussian, fit_gaussian2]:\n",
    "        current = fit(x_)\n",
    "        x_ -= current\n",
    "        gaussians.append(current)\n",
    "    gaussians = np.array(gaussians)\n",
    "    return np.sum(gaussians, axis=0)\n",
    "\n",
    "#faster approximation\n",
    "def preliminary_photo_approximation(x):\n",
    "    spline_appr = 5e9\n",
    "    ifft_appr = 1e6\n",
    "    space = np.arange(x.shape[0])\n",
    "\n",
    "    lst = []\n",
    "    for min_HWHM in [100,150,200,250]:\n",
    "        k = int((wavenumbers[-1] - wavenumbers[0]) / (2*min_HWHM))\n",
    "\n",
    "        fourier = fft(x)\n",
    "        fourier_real = fourier.real\n",
    "        fourier_imag = fourier.imag\n",
    "\n",
    "        func = interpolate.UnivariateSpline(space, fourier_real, k=4, s=spline_appr)\n",
    "        fourier_real[k:-k] = func(space[k:-k])\n",
    "        if sum(np.isnan(fourier_real[k:-k])):\n",
    "            fourier_real[k:-k] = 0\n",
    "            \n",
    "        func = interpolate.UnivariateSpline(space, fourier_imag, k=4, s=spline_appr)\n",
    "        fourier_imag[k:-k] = func(space[k:-k])\n",
    "        if sum(np.isnan(fourier_imag[k:-k])):\n",
    "            fourier_imag[k:-k] = 0\n",
    "            \n",
    "        smooth_fourier = fourier_real + 1j * fourier_imag\n",
    "        lst.append(ifft(smooth_fourier))\n",
    "\n",
    "    lst = np.min(np.array(lst), 0)\n",
    "    fourier = fft(lst)\n",
    "    fourier_real = fourier.real\n",
    "    fourier_imag = fourier.imag\n",
    "\n",
    "    func = interpolate.UnivariateSpline(space, fourier_real, k=4, s=spline_appr)\n",
    "    fourier_real[k:-k] = func(space[k:-k])\n",
    "\n",
    "    func = interpolate.UnivariateSpline(space, fourier_imag, k=4, s=spline_appr)\n",
    "    fourier_imag[k:-k] = func(space[k:-k])\n",
    "\n",
    "    smooth_fourier = fourier_real + 1j * fourier_imag\n",
    "    x = ifft(smooth_fourier)\n",
    "    \n",
    "    func = interpolate.UnivariateSpline(space, x, k=4, s=ifft_appr)\n",
    "    return func(space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2727cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_bound_to_None(bound):\n",
    "    # -0 must be translate to None\n",
    "    return -bound if bound != 0 else None\n",
    "\n",
    "def init_smooth_grad(general_noise=10e6, continue_gap=100):\n",
    "    def smooth_grad(poly2):\n",
    "        general_grad_func = interpolate.UnivariateSpline(wavenumbers, \n",
    "                                                         poly2,\n",
    "                                                         k=3, s=general_noise)\n",
    "        general_grad = general_grad_func(wavenumbers)\n",
    "        grad_general = general_grad[1:] - general_grad[:-1]\n",
    "\n",
    "        grad = poly2[1:] - poly2[:-1]        \n",
    "        grad2 = np.pad(poly2[2:] - 2 * poly2[1:-1] + poly2[:-2],(1, 0), 'edge')\n",
    "\n",
    "        general_max_lst = signal.argrelmax(grad_general)[0]\n",
    "        max_lst = signal.argrelmax(grad)[0]\n",
    "        max_grad_lst = signal.argrelmax(grad2)[0]\n",
    "        min_grad_lst = signal.argrelmin(grad2)[0]\n",
    "\n",
    "        for max_ in max_lst:\n",
    "            if general_max_lst is []:\n",
    "                general_max = general_max_lst[np.argmin([abs(x - max_) for x in general_max_lst])]\n",
    "                if abs(general_max - max_) < continue_gap/2:\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                *_, left = filter(lambda x: x < max_, max_grad_lst)\n",
    "                right = next(filter(lambda x: x > max_, min_grad_lst))\n",
    "            except (ValueError, StopIteration) as error:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                *_, left_max = filter(lambda x: x < max_, max_lst)\n",
    "            except ValueError:\n",
    "                left_max = 0\n",
    "\n",
    "            try:\n",
    "                right_max = next(filter(lambda x: x > max_, max_lst))\n",
    "            except StopIteration:\n",
    "                right_max = grad.shape[0]          \n",
    "\n",
    "            old_sum = sum(grad)\n",
    "            restore_grad = copy.copy(grad)\n",
    "            grad[left:max_] = grad[left]\n",
    "            new_sum = sum(grad)\n",
    "            i = max_\n",
    "\n",
    "            dist = 3 * min(max_ - left, right - max_)\n",
    "            dist = min(dist, max_ - left_max, right_max - max_)\n",
    "\n",
    "            while True:\n",
    "                while new_sum < old_sum:\n",
    "                    grad[i:i+10] = grad[left]\n",
    "                    new_sum = sum(grad)\n",
    "                    i += 10\n",
    "                    if i > min(max_ + dist, grad.shape[0]):\n",
    "                        left = min(left+10, grad.shape[0]-1) #to prevent left going out of bounds\n",
    "                        grad = copy.copy(restore_grad)\n",
    "                        grad[left:max_] = grad[left]\n",
    "                        new_sum = sum(grad)\n",
    "                        i = max_\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            flat_residu = (old_sum - new_sum) / (left-i)\n",
    "            grad[left:i] -= flat_residu\n",
    "\n",
    "            # if flatting of the maximum gradient is not possible skip\n",
    "            if left >= max_:\n",
    "                continue\n",
    "\n",
    "            smooth_dist = max(2, min(i-left, continue_gap))\n",
    "            sigma = smooth_dist/4\n",
    "            smooth_dist2 = smooth_dist//2\n",
    "            smooth_dist2b = smooth_dist - smooth_dist2\n",
    "            smooth_dist3 = smooth_dist + smooth_dist2\n",
    "            if left-smooth_dist3 < 0: # correct for maximums at the left part of the spectrum\n",
    "                left_bound, gaus_left_bound = max(0, left-smooth_dist2), max(0, left-smooth_dist)\n",
    "                grad[left_bound:i+smooth_dist2] = ndimage.gaussian_filter(grad[gaus_left_bound:i+smooth_dist], sigma, mode='nearest')[left_bound - gaus_left_bound:-smooth_dist2b]\n",
    "                left_bound = max(0, left-smooth_dist)\n",
    "                grad[left_bound: left+smooth_dist] = ndimage.gaussian_filter(grad[:left+smooth_dist3], sigma, mode='nearest')[left_bound:-smooth_dist2]\n",
    "                left_bound, gaus_left_bound = max(0, i-smooth_dist), max(0, i-smooth_dist3)\n",
    "                grad[left_bound:i+smooth_dist] = ndimage.gaussian_filter(grad[gaus_left_bound:i+smooth_dist3], sigma, mode='nearest')[left_bound - gaus_left_bound:-smooth_dist2]\n",
    "            elif i + smooth_dist3 > grad.shape[0]: # correct for maximums at the right part of the spectrum\n",
    "                right_bound, gaus_right_bound = max(grad.shape[0] - (i+smooth_dist2), 0), max(grad.shape[0] - (i+smooth_dist), 0)\n",
    "                right_diff = right_bound - gaus_right_bound\n",
    "                right_bound, gaus_right_bound, right_diff = zero_bound_to_None(right_bound), zero_bound_to_None(gaus_right_bound), zero_bound_to_None(right_diff)\n",
    "                grad[left-smooth_dist2:right_bound] = ndimage.gaussian_filter(grad[left-smooth_dist:gaus_right_bound], sigma, mode='nearest')[smooth_dist2b:right_diff]\n",
    "                right_bound, gaus_right_bound = max(grad.shape[0] - (left+smooth_dist), 0), max(grad.shape[0] - (left+smooth_dist3), 0)\n",
    "                right_diff = right_bound - gaus_right_bound\n",
    "                right_bound, gaus_right_bound, right_diff = zero_bound_to_None(right_bound), zero_bound_to_None(gaus_right_bound), zero_bound_to_None(right_diff)\n",
    "                grad[left-smooth_dist:right_bound] = ndimage.gaussian_filter(grad[left-smooth_dist3:min(left+smooth_dist3, grad.shape[0])], sigma, mode='nearest')[smooth_dist2:right_diff]\n",
    "                right_bound = max(grad.shape[0] - (i+smooth_dist), 0)\n",
    "                right_bound = zero_bound_to_None(right_bound)\n",
    "                grad[i-smooth_dist:right_bound] = ndimage.gaussian_filter(grad[i-smooth_dist3:], sigma, mode='nearest')[smooth_dist2:right_bound]\n",
    "            else:\n",
    "                grad[left-smooth_dist2:i+smooth_dist2] = ndimage.gaussian_filter(grad[left-smooth_dist:i+smooth_dist], sigma, mode='nearest')[smooth_dist2b:-smooth_dist2b]            \n",
    "                grad[left-smooth_dist:left+smooth_dist] = ndimage.gaussian_filter(grad[left-smooth_dist3:left+smooth_dist3], sigma, mode='nearest')[smooth_dist2:-smooth_dist2]\n",
    "                grad[i-smooth_dist:i+smooth_dist] = ndimage.gaussian_filter(grad[i-smooth_dist3:i+smooth_dist3], sigma, mode='nearest')[smooth_dist2:-smooth_dist2]\n",
    "\n",
    "            new_sum = sum(grad)\n",
    "            left_bound, right_bound = max(0,left-smooth_dist), min(i+smooth_dist, grad.shape[0])\n",
    "            flat_residu = (old_sum - new_sum) / (left_bound - right_bound)\n",
    "            grad[left_bound: right_bound] -= flat_residu\n",
    "\n",
    "        value = poly2[0]\n",
    "        poly2 = [value]\n",
    "        for g in grad:\n",
    "            value += g\n",
    "            poly2.append(value)\n",
    "            \n",
    "        return np.array(poly2)\n",
    "    return smooth_grad\n",
    "\n",
    "smooth_grad = init_smooth_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce72507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_poly_approximation(general_noise=50e6, continue_gap=100, intervals=10, precision=12, poly_fit=1e5):\n",
    "    def poly_approximation(x, general):\n",
    "        general_grad_func = interpolate.UnivariateSpline(wavenumbers, \n",
    "                                                         general,\n",
    "                                                         k=4, s=general_noise)\n",
    "        general_grad = general_grad_func(wavenumbers)\n",
    "        sec_grad2 = np.pad(general_grad[2:] - 2*general_grad[1:-1] + general_grad[:-2], (1, 1), 'edge')\n",
    "        grad = np.pad(general[1:] - general[:-1], (0,1), 'edge')\n",
    "        grad_m = np.mean(np.abs(grad))\n",
    "        small_grad = np.abs(grad) < grad_m\n",
    "        sec_grad_pos = (sec_grad2 < 0)\n",
    "\n",
    "        small_grad = ndimage.minimum_filter(small_grad, size=continue_gap)\n",
    "        sec_grad_pos = ndimage.minimum_filter(sec_grad_pos, size=continue_gap)\n",
    "        small_grad = ndimage.maximum_filter(small_grad, size=continue_gap)\n",
    "        sec_grad_pos = ndimage.maximum_filter(sec_grad_pos, size=continue_gap)\n",
    "        logic = sec_grad_pos * small_grad\n",
    "\n",
    "        sec_grad_sign = ndimage.gaussian_filter(logic.astype(np.float32), 50)       \n",
    "\n",
    "        minimums = []\n",
    "        step = x.shape[0]//intervals\n",
    "        for j in range(0, step, step//precision):\n",
    "            x_ = copy.copy(x)\n",
    "            # to adress exponential values at the left side of the spectrum, make these value higher\n",
    "            if j > 0:\n",
    "                new_step = x_[:j].shape[0]\n",
    "                slope = general[:j]\n",
    "                height = slope[-1] - slope[0]\n",
    "                slope = np.linspace(0, height, new_step)\n",
    "                index = np.argmin(x_[:j] - slope)\n",
    "                slope -= slope[index]\n",
    "                slope += x[index]\n",
    "                x_[:j] = slope\n",
    "\n",
    "            for i in range(j, x.shape[0]-1, step):\n",
    "                step_size = step\n",
    "                new_step = x_[i:i+step_size].shape[0]\n",
    "                smooth_curve = general[i:i+new_step]\n",
    "                height = smooth_curve[-1] - smooth_curve[0]\n",
    "                slope = np.linspace(0, height, new_step)\n",
    "                index = np.argmin(x_[i:i+new_step] - slope)\n",
    "                slope -= slope[index]\n",
    "                slope += x[i+index]\n",
    "                x_[i:i+new_step] = slope\n",
    "            minimums.append(x_)\n",
    "\n",
    "        poly_max = np.max(np.array(minimums), axis=0)\n",
    "        poly_min = np.min(np.array(minimums), axis=0)\n",
    "        poly = sec_grad_sign * poly_min + (1-sec_grad_sign) * poly_max\n",
    "\n",
    "        old_poly = poly-1\n",
    "        j = 0\n",
    "        while sum(poly-old_poly) and j < 5:\n",
    "            j += 1\n",
    "            func = interpolate.UnivariateSpline(wavenumbers, \n",
    "                                                poly,\n",
    "                                                k=4, s=poly_fit)\n",
    "            poly2 = func(wavenumbers)\n",
    "\n",
    "            old_poly = copy.copy(poly)\n",
    "            \"\"\"\n",
    "            This pushes the poly graph down acting like a weight for the spline to fit the graph below x\n",
    "            \"\"\"\n",
    "            problem_part = ndimage.maximum_filter(ndimage.minimum_filter(poly2 > x, 3), continue_gap//5)\n",
    "            poly -= problem_part * 5\n",
    "        poly2 = smooth_grad(poly2)\n",
    "\n",
    "        return poly2\n",
    "    return poly_approximation\n",
    "poly_approximation = init_poly_approximation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab505aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_signal(img):\n",
    "    \"\"\" \n",
    "    img consists of data and label\n",
    "    \n",
    "    artefact due to using previous points \n",
    "    \n",
    "    \"\"\"\n",
    "    x = img[0].reshape(-1, img[0].shape[-1])\n",
    "    \n",
    "    raman = np.empty(x.shape)\n",
    "    photo = np.empty(x.shape)\n",
    "    start = timeit.default_timer()\n",
    "    for pixel in range(x.shape[0]):\n",
    "        # poly approximation\n",
    "        poly = preliminary_photo_approximation(x[pixel])\n",
    "        poly2 = smooth_grad(poly)\n",
    "        for i in range(3):\n",
    "            poly2 = poly_approximation(x[pixel], poly2)\n",
    "\n",
    "        # raman approximation\n",
    "        raman2 = remove_noise_fft(x[pixel]-poly2)\n",
    "        \n",
    "        raman[pixel] = raman2\n",
    "        photo[pixel] = poly2\n",
    "        if not pixel % 100:\n",
    "            stop = timeit.default_timer()\n",
    "            print(f\"progress = {100* pixel / x.shape[0]}%, 100 samples time : {stop - start}\")\n",
    "            start = timeit.default_timer()\n",
    "        \n",
    "    return raman, photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a53174a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liver_map_150z25_60s_#6.npy\n",
      "progress = 0.0%, 100 samples time : 0.30150374900040333\n",
      "progress = 2.6666666666666665%, 100 samples time : 25.971079172000827\n",
      "progress = 5.333333333333333%, 100 samples time : 20.809879761999582\n",
      "progress = 8.0%, 100 samples time : 20.831102140999974\n",
      "progress = 10.666666666666666%, 100 samples time : 19.273994326999855\n",
      "progress = 13.333333333333334%, 100 samples time : 20.481737480999982\n",
      "progress = 16.0%, 100 samples time : 21.118854915000156\n",
      "progress = 18.666666666666668%, 100 samples time : 19.581256116000077\n",
      "progress = 21.333333333333332%, 100 samples time : 19.30587086899959\n",
      "progress = 24.0%, 100 samples time : 20.41807141499976\n",
      "progress = 26.666666666666668%, 100 samples time : 19.90150016000007\n",
      "progress = 29.333333333333332%, 100 samples time : 21.728676370999892\n",
      "progress = 32.0%, 100 samples time : 21.455122306000703\n",
      "progress = 34.666666666666664%, 100 samples time : 24.740285080999456\n",
      "progress = 37.333333333333336%, 100 samples time : 19.369247655000436\n",
      "progress = 40.0%, 100 samples time : 19.979102541999964\n",
      "progress = 42.666666666666664%, 100 samples time : 19.11694934500065\n",
      "progress = 45.333333333333336%, 100 samples time : 29.140097452999726\n",
      "progress = 48.0%, 100 samples time : 21.748653953999565\n",
      "progress = 50.666666666666664%, 100 samples time : 24.897004913000274\n",
      "progress = 53.333333333333336%, 100 samples time : 24.700050002998978\n",
      "progress = 56.0%, 100 samples time : 21.728114083000037\n",
      "progress = 58.666666666666664%, 100 samples time : 21.48755604500002\n",
      "progress = 61.333333333333336%, 100 samples time : 23.3198023570003\n",
      "progress = 64.0%, 100 samples time : 22.341032459000417\n",
      "progress = 66.66666666666667%, 100 samples time : 22.39024001799953\n",
      "progress = 69.33333333333333%, 100 samples time : 27.0808966099994\n",
      "progress = 72.0%, 100 samples time : 27.427148054999634\n",
      "progress = 74.66666666666667%, 100 samples time : 24.008321311001055\n",
      "progress = 77.33333333333333%, 100 samples time : 24.44904137999947\n",
      "progress = 80.0%, 100 samples time : 23.784335758000452\n",
      "progress = 82.66666666666667%, 100 samples time : 23.46679101100017\n",
      "progress = 85.33333333333333%, 100 samples time : 21.203454411001076\n",
      "progress = 88.0%, 100 samples time : 22.71248577500046\n",
      "progress = 90.66666666666667%, 100 samples time : 20.886086933000115\n",
      "progress = 93.33333333333333%, 100 samples time : 21.634314347998952\n",
      "progress = 96.0%, 100 samples time : 28.4855060280006\n",
      "progress = 98.66666666666667%, 100 samples time : 22.064597235999827\n",
      "Time:  844.8430270029994\n",
      "image: Liver_map_150z25_60s_#6.npy is done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Liver_map_150z25_60s_#17.npy\n",
    "31 x 2  and 31 x 8\n",
    "Liver_map_150z25_60s_#6.npy\n",
    "107 x 21\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "file_location2 = f\"{'/'.join(file_location.split('/')[:-2])}/approximated_curve_fit/\"\n",
    "os.makedirs(file_location2, exist_ok=True)\n",
    "\n",
    "shape = data[0][0].shape\n",
    "\n",
    "for j, (f, img) in enumerate(zip(filenames, data)):   \n",
    "    start = timeit.default_timer()\n",
    "    if f != 'Liver_map_150z25_60s_#6.npy':\n",
    "        continue\n",
    "        \n",
    "    print(f)\n",
    "#     if path.exists(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman.npy'):\n",
    "#         print(f'file already exist {file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman')\n",
    "#         continue\n",
    "\n",
    "    raman, photo = split_signal(img)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', stop - start)  \n",
    "\n",
    "    np.save(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman', raman.reshape(shape))\n",
    "    np.save(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_photoluminescence', photo.reshape(shape))\n",
    "    print(f\"image: {f} is done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5542c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ca348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f04ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
