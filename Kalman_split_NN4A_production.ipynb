{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fabde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from scipy import ndimage\n",
    "from BaselineRemoval import BaselineRemoval\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50bb9d",
   "metadata": {},
   "source": [
    "Mogelijke verbeteringen:\n",
    " - maak de covariance afhankelijke van de noise \n",
    " - draai de spectrum zodanig dat de globale sloop de x-as is. Zodat het min-max algorithme beter werkt. DONE\n",
    " - de smoothing die applied wordt door de covariantie moet afgesteld worden per sample\n",
    "\n",
    "Problemen:\n",
    " - initializatie maakt uit voor de kalman smoother (hoeveel noise er is vs raman)\n",
    " - aantal iteratie maakt uit voor de kalman smoother (hoeveel noise er is vs raman)\n",
    " - de bounderies hebben geen invloed op de kalman smoother buiten alles binnen de bounderies houden.\n",
    "   Tenzij smoothing ook aanstaat.\n",
    "   \n",
    "   \n",
    "excitation laser maakt uit hoe de raman laser eruit ziet. Hoger (rood) betekend lower raman signal en een breder signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f53ed",
   "metadata": {},
   "source": [
    "date: 2-9-2022\n",
    "\n",
    " - stabilise the logic part with neighbourhood information\n",
    " - where the logic part is true make the line segments bigger (does not work)\n",
    " - find something to deterime the smoothness of the poly fit (no bumbs) DONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c14c35",
   "metadata": {},
   "source": [
    "### Ideas:\n",
    "\n",
    "- Wavelet transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73d522",
   "metadata": {},
   "source": [
    "### Errors:\n",
    "\n",
    " - smooth_grad fix the try except clause such that and the beginning and end of the spectrum it also works\n",
    " - using fourier transform it seems that gibbs phenomena is a problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c89bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"../data/Raman_Mouse/corrected_4_wavenumbers/\"\n",
    "# file_location = \"../data/Green_excitation/corrected_4_wavenumbers/\"\n",
    "\n",
    "filenames = np.load(f\"{file_location}FileNames.npy\")\n",
    "with open(f\"{'/'.join(file_location.split('/')[:-2])}/Sample_labels.pickle\", 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "labels = {l.split(\".\")[0]: val for l, val in labels.items()}\n",
    "\n",
    "wavenumbers = np.load(f\"{file_location}Wavenumbers.npy\")\n",
    "    \n",
    "data = []\n",
    "for f in filenames:\n",
    "    x = np.load(f\"{file_location}{f.split('.')[0]}.npy\")\n",
    "    data.append(((x.reshape(-1,x.shape[-1])).reshape(x.shape), labels[f.split(\".\")[0]]))\n",
    "    \n",
    "# #mouse image\n",
    "# noise_amount = 1e5\n",
    "# intervals = 10\n",
    "# general_noise = 10e6\n",
    "# poly_fit = 1e5\n",
    "# precision = 12\n",
    "# continue_gap = 100\n",
    "# # green image\n",
    "# noise_amount = 3e5\n",
    "# general_noise = 5e6\n",
    "# intervals = 30\n",
    "# precision = 20\n",
    "# poly_fit = 8e5\n",
    "# continue_gap = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89283988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise_fft_min(min_HWHM=5, spline_appr=5e9):\n",
    "    k = int((wavenumbers[-1] - wavenumbers[0]) / (2*min_HWHM))\n",
    "    def remove_noise_fft(x):       \n",
    "        x_ = copy.copy(x)\n",
    "        mean = np.mean(x)\n",
    "        x_ -= mean\n",
    "        fourier = fft(x_)\n",
    "\n",
    "        fourier_real = fourier.real\n",
    "        fourier_imag = fourier.imag\n",
    "        \n",
    "        space = np.arange(x.shape[0])\n",
    "\n",
    "        func = interpolate.UnivariateSpline(space, fourier_real, k=4, s=spline_appr)\n",
    "        fourier_real[k:-k] = func(space[k:-k])\n",
    "\n",
    "        func = interpolate.UnivariateSpline(space, fourier_imag, k=4, s=spline_appr)\n",
    "        fourier_imag[k:-k] = func(space[k:-k])\n",
    "\n",
    "        smooth_fourier = fourier_real + 1j * fourier_imag\n",
    "\n",
    "        return ifft(smooth_fourier) + mean\n",
    "    return remove_noise_fft\n",
    "remove_noise_fft = remove_noise_fft_min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f2690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma, scale):\n",
    "    x = scale * np.exp(-0.5* ((x - mu) / sigma)**2)\n",
    "    return x * (x > min(scale/10, 10))\n",
    "\n",
    "def init_fit_gaussian(min_wavenumber=-1000, left_steps=10, min_sigma=100, max_sigma=1500, steps=20):\n",
    "    def fit_gaussian(x):\n",
    "        lst = []\n",
    "        for mu in np.concatenate((np.linspace(-min_wavenumber, 0, left_steps), np.linspace(wavenumbers[0], wavenumbers[-1], steps))):\n",
    "            temp_mu = 0,1,1\n",
    "            temp_intergral = 0\n",
    "            for sigma in np.linspace(min_sigma**0.5, max_sigma**0.5, steps)**2:\n",
    "                if mu < 0 and mu + 3*sigma < 0:\n",
    "                    continue\n",
    "\n",
    "                scale = 10\n",
    "                current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "\n",
    "                for delta in 10**np.arange(10, -1, -1):\n",
    "                    while not np.sum((current - x) > 0):\n",
    "                        scale += delta\n",
    "                        current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "                    else:\n",
    "                        scale -= delta\n",
    "                        current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "\n",
    "                intergral = np.sum(current)\n",
    "                if intergral > temp_intergral:\n",
    "                    temp_intergral = intergral\n",
    "                    temp_mu = mu, sigma, scale\n",
    "\n",
    "            if temp_mu[1] < min_sigma: #no fit found\n",
    "                continue\n",
    "\n",
    "            for sigma in np.linspace(max(min_sigma, temp_mu[1]-50), temp_mu[1]+50, steps):\n",
    "                if mu < 0 and mu + 3*sigma < 0:\n",
    "                    continue\n",
    "                scale = 10\n",
    "                current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "\n",
    "                for delta in 10**np.arange(10, -1, -1):\n",
    "                    while not np.sum((current - x) > 0):\n",
    "                        scale += delta\n",
    "                        current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "                    else:\n",
    "                        scale -= delta\n",
    "                        current = gaussian(wavenumbers, mu, sigma, scale)\n",
    "\n",
    "                intergral = np.sum(current)\n",
    "                if intergral > temp_intergral:\n",
    "                    temp_intergral = intergral\n",
    "                    temp_mu = mu, sigma, scale\n",
    "\n",
    "            lst.append(gaussian(wavenumbers, *temp_mu))\n",
    "        lst = np.array(lst)\n",
    "        return np.max(lst, axis=0)\n",
    "    return fit_gaussian\n",
    "    \n",
    "def preliminary_photo_approximation(x):\n",
    "    fit_gaussian = init_fit_gaussian()\n",
    "    fit_gaussian2 = init_fit_gaussian(left_steps=0)\n",
    "    \n",
    "    x_ = copy.copy(x)\n",
    "    gaussians = []   \n",
    "    for fit in [fit_gaussian, fit_gaussian2]:\n",
    "        current = fit(x_)\n",
    "        x_ -= current\n",
    "        gaussians.append(current)\n",
    "    gaussians = np.array(gaussians)\n",
    "    return np.sum(gaussians, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d4b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_bound_to_None(bound):\n",
    "    # -0 must be translate to None\n",
    "    return -bound if bound != 0 else None\n",
    "\n",
    "def init_smooth_grad(general_noise=10e6, continue_gap=100):\n",
    "    def smooth_grad(poly2):\n",
    "        general_grad_func = interpolate.UnivariateSpline(wavenumbers, \n",
    "                                                         poly2,\n",
    "                                                         k=3, s=general_noise)\n",
    "        general_grad = general_grad_func(wavenumbers)\n",
    "        grad_general = general_grad[1:] - general_grad[:-1]\n",
    "\n",
    "        grad = poly2[1:] - poly2[:-1]        \n",
    "        grad2 = np.pad(poly2[2:] - 2 * poly2[1:-1] + poly2[:-2],(1, 0), 'edge')\n",
    "\n",
    "        general_max_lst = signal.argrelmax(grad_general)[0]\n",
    "        max_lst = signal.argrelmax(grad)[0]\n",
    "        max_grad_lst = signal.argrelmax(grad2)[0]\n",
    "        min_grad_lst = signal.argrelmin(grad2)[0]\n",
    "\n",
    "        for max_ in max_lst:\n",
    "            general_max = general_max_lst[np.argmin([abs(x - max_) for x in general_max_lst])]\n",
    "            if abs(general_max - max_) < continue_gap/2:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                *_, left = filter(lambda x: x < max_, max_grad_lst)\n",
    "                right = next(filter(lambda x: x > max_, min_grad_lst))\n",
    "            except (ValueError, StopIteration) as error:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                *_, left_max = filter(lambda x: x < max_, max_lst)\n",
    "            except ValueError:\n",
    "                left_max = 0\n",
    "\n",
    "            try:\n",
    "                right_max = next(filter(lambda x: x > max_, max_lst))\n",
    "            except StopIteration:\n",
    "                right_max = grad.shape[0]          \n",
    "\n",
    "            old_sum = sum(grad)\n",
    "            restore_grad = copy.copy(grad)\n",
    "            grad[left:max_] = grad[left]\n",
    "            new_sum = sum(grad)\n",
    "            i = max_\n",
    "\n",
    "            dist = 3 * min(max_ - left, right - max_)\n",
    "            dist = min(dist, max_ - left_max, right_max - max_)\n",
    "\n",
    "            while True:\n",
    "                while new_sum < old_sum:\n",
    "                    grad[i:i+10] = grad[left]\n",
    "                    new_sum = sum(grad)\n",
    "                    i += 10\n",
    "                    if i > min(max_ + dist, grad.shape[0]):\n",
    "                        left = min(left+10, grad.shape[0]-1) #to prevent left going out of bounds\n",
    "                        grad = copy.copy(restore_grad)\n",
    "                        grad[left:max_] = grad[left]\n",
    "                        new_sum = sum(grad)\n",
    "                        i = max_\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            flat_residu = (old_sum - new_sum) / (left-i)\n",
    "            grad[left:i] -= flat_residu\n",
    "\n",
    "            # if flatting of the maximum gradient is not possible skip\n",
    "            if left >= max_:\n",
    "                continue\n",
    "\n",
    "            smooth_dist = max(2, min(i-left, continue_gap))\n",
    "            sigma = smooth_dist/4\n",
    "            smooth_dist2 = smooth_dist//2\n",
    "            smooth_dist2b = smooth_dist - smooth_dist2\n",
    "            smooth_dist3 = smooth_dist + smooth_dist2\n",
    "            if left-smooth_dist3 < 0: # correct for maximums at the left part of the spectrum\n",
    "                left_bound, gaus_left_bound = max(0, left-smooth_dist2), max(0, left-smooth_dist)\n",
    "                grad[left_bound:i+smooth_dist2] = ndimage.gaussian_filter(grad[gaus_left_bound:i+smooth_dist], sigma, mode='nearest')[left_bound - gaus_left_bound:-smooth_dist2b]\n",
    "                left_bound = max(0, left-smooth_dist)\n",
    "                grad[left_bound: left+smooth_dist] = ndimage.gaussian_filter(grad[:left+smooth_dist3], sigma, mode='nearest')[left_bound:-smooth_dist2]\n",
    "                left_bound, gaus_left_bound = max(0, i-smooth_dist), max(0, i-smooth_dist3)\n",
    "                grad[left_bound:i+smooth_dist] = ndimage.gaussian_filter(grad[gaus_left_bound:i+smooth_dist3], sigma, mode='nearest')[left_bound - gaus_left_bound:-smooth_dist2]\n",
    "            elif i + smooth_dist3 > grad.shape[0]: # correct for maximums at the right part of the spectrum\n",
    "                right_bound, gaus_right_bound = max(grad.shape[0] - (i+smooth_dist2), 0), max(grad.shape[0] - (i+smooth_dist), 0)\n",
    "                right_diff = right_bound - gaus_right_bound\n",
    "                right_bound, gaus_right_bound, right_diff = zero_bound_to_None(right_bound), zero_bound_to_None(gaus_right_bound), zero_bound_to_None(right_diff)\n",
    "                grad[left-smooth_dist2:right_bound] = ndimage.gaussian_filter(grad[left-smooth_dist:gaus_right_bound], sigma, mode='nearest')[smooth_dist2b:right_diff]\n",
    "                right_bound, gaus_right_bound = max(grad.shape[0] - (left+smooth_dist), 0), max(grad.shape[0] - (left+smooth_dist3), 0)\n",
    "                right_diff = right_bound - gaus_right_bound\n",
    "                right_bound, gaus_right_bound, right_diff = zero_bound_to_None(right_bound), zero_bound_to_None(gaus_right_bound), zero_bound_to_None(right_diff)\n",
    "                grad[left-smooth_dist:right_bound] = ndimage.gaussian_filter(grad[left-smooth_dist3:min(left+smooth_dist3, grad.shape[0])], sigma, mode='nearest')[smooth_dist2:right_diff]\n",
    "                right_bound = max(grad.shape[0] - (i+smooth_dist), 0)\n",
    "                right_bound = zero_bound_to_None(right_bound)\n",
    "                grad[i-smooth_dist:right_bound] = ndimage.gaussian_filter(grad[i-smooth_dist3:], sigma, mode='nearest')[smooth_dist2:right_bound]\n",
    "            else:\n",
    "                grad[left-smooth_dist2:i+smooth_dist2] = ndimage.gaussian_filter(grad[left-smooth_dist:i+smooth_dist], sigma, mode='nearest')[smooth_dist2b:-smooth_dist2b]            \n",
    "                grad[left-smooth_dist:left+smooth_dist] = ndimage.gaussian_filter(grad[left-smooth_dist3:left+smooth_dist3], sigma, mode='nearest')[smooth_dist2:-smooth_dist2]\n",
    "                grad[i-smooth_dist:i+smooth_dist] = ndimage.gaussian_filter(grad[i-smooth_dist3:i+smooth_dist3], sigma, mode='nearest')[smooth_dist2:-smooth_dist2]\n",
    "\n",
    "            new_sum = sum(grad)\n",
    "            left_bound, right_bound = max(0,left-smooth_dist), min(i+smooth_dist, grad.shape[0])\n",
    "            flat_residu = (old_sum - new_sum) / (left_bound - right_bound)\n",
    "            grad[left_bound: right_bound] -= flat_residu\n",
    "\n",
    "        value = poly2[0]\n",
    "        poly2 = [value]\n",
    "        for g in grad:\n",
    "            value += g\n",
    "            poly2.append(value)\n",
    "            \n",
    "        return np.array(poly2)\n",
    "    return smooth_grad\n",
    "\n",
    "smooth_grad = init_smooth_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0044864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_poly_approximation(general_noise=50e6, continue_gap=100, intervals=10, precision=12, poly_fit=1e5):\n",
    "    def poly_approximation(x, general):\n",
    "        general_grad_func = interpolate.UnivariateSpline(wavenumbers, \n",
    "                                                         general,\n",
    "                                                         k=4, s=general_noise)\n",
    "        general_grad = general_grad_func(wavenumbers)\n",
    "        sec_grad2 = np.pad(general_grad[2:] - 2*general_grad[1:-1] + general_grad[:-2], (1, 1), 'edge')\n",
    "        grad = np.pad(general[1:] - general[:-1], (0,1), 'edge')\n",
    "        grad_m = np.mean(np.abs(grad))\n",
    "        small_grad = np.abs(grad) < grad_m\n",
    "        sec_grad_pos = (sec_grad2 < 0)\n",
    "\n",
    "        small_grad = ndimage.minimum_filter(small_grad, size=continue_gap)\n",
    "        sec_grad_pos = ndimage.minimum_filter(sec_grad_pos, size=continue_gap)\n",
    "        small_grad = ndimage.maximum_filter(small_grad, size=continue_gap)\n",
    "        sec_grad_pos = ndimage.maximum_filter(sec_grad_pos, size=continue_gap)\n",
    "        logic = sec_grad_pos * small_grad\n",
    "\n",
    "        sec_grad_sign = ndimage.gaussian_filter(logic.astype(np.float32), 50)       \n",
    "\n",
    "        minimums = []\n",
    "        step = x.shape[0]//intervals\n",
    "        for j in range(0, step, step//precision):\n",
    "            x_ = copy.copy(x)\n",
    "            # to adress exponential values at the left side of the spectrum, make these value higher\n",
    "            if j > 0:\n",
    "                new_step = x_[:j].shape[0]\n",
    "                slope = general[:j]\n",
    "                height = slope[-1] - slope[0]\n",
    "                slope = np.linspace(0, height, new_step)\n",
    "                index = np.argmin(x_[:j] - slope)\n",
    "                slope -= slope[index]\n",
    "                slope += x[index]\n",
    "                x_[:j] = slope\n",
    "\n",
    "            for i in range(j, x.shape[0]-1, step):\n",
    "                step_size = step\n",
    "                new_step = x_[i:i+step_size].shape[0]\n",
    "                smooth_curve = general[i:i+new_step]\n",
    "                height = smooth_curve[-1] - smooth_curve[0]\n",
    "                slope = np.linspace(0, height, new_step)\n",
    "                index = np.argmin(x_[i:i+new_step] - slope)\n",
    "                slope -= slope[index]\n",
    "                slope += x[i+index]\n",
    "                x_[i:i+new_step] = slope\n",
    "            minimums.append(x_)\n",
    "\n",
    "        poly_max = np.max(np.array(minimums), axis=0)\n",
    "        poly_min = np.min(np.array(minimums), axis=0)\n",
    "        poly = sec_grad_sign * poly_min + (1-sec_grad_sign) * poly_max\n",
    "\n",
    "        old_poly = poly-1\n",
    "        j = 0\n",
    "        while sum(poly-old_poly) and j < 5:\n",
    "            j += 1\n",
    "            func = interpolate.UnivariateSpline(wavenumbers, \n",
    "                                                poly,\n",
    "                                                k=4, s=poly_fit)\n",
    "            poly2 = func(wavenumbers)\n",
    "\n",
    "            old_poly = copy.copy(poly)\n",
    "            \"\"\"\n",
    "            This pushes the poly graph down acting like a weight for the spline to fit the graph below x\n",
    "            \"\"\"\n",
    "            problem_part = ndimage.maximum_filter(ndimage.minimum_filter(poly2 > x, 3), continue_gap//5)\n",
    "            poly -= problem_part * 5\n",
    "        poly2 = smooth_grad(poly2)\n",
    "\n",
    "        return poly2\n",
    "    return poly_approximation\n",
    "poly_approximation = init_poly_approximation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68f842c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_signal(img):\n",
    "    \"\"\" \n",
    "    img consists of data and label\n",
    "    \n",
    "    artefact due to using previous points \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    x = img[0].reshape(-1, img[0].shape[-1])\n",
    "    \n",
    "    raman = np.empty(x.shape)\n",
    "    photo = np.empty(x.shape)\n",
    "    for pixel in range(x.shape[0]):\n",
    "#         if not pixel % 10:\n",
    "        print(f\"progress = {100* pixel / x.shape[0]}%\")\n",
    "        # poly approximation\n",
    "        poly = preliminary_photo_approximation(x[pixel])\n",
    "        poly2 = smooth_grad(poly)\n",
    "        for i in range(3):\n",
    "            poly2 = poly_approximation(x[pixel], poly2)\n",
    "\n",
    "        # raman approximation\n",
    "        raman2 = remove_noise_fft(x[pixel]-poly2)\n",
    "\n",
    "        raman[pixel] = raman2\n",
    "        photo[pixel] = poly2\n",
    "        \n",
    "    return raman, photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cac801d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 0.0%\n",
      "progress = 0.02666666666666667%\n",
      "progress = 0.05333333333333334%\n",
      "progress = 0.08%\n",
      "progress = 0.10666666666666667%\n",
      "progress = 0.13333333333333333%\n",
      "progress = 0.16%\n",
      "progress = 0.18666666666666668%\n",
      "progress = 0.21333333333333335%\n",
      "progress = 0.24%\n",
      "progress = 0.26666666666666666%\n",
      "progress = 0.29333333333333333%\n",
      "progress = 0.32%\n",
      "progress = 0.3466666666666667%\n",
      "progress = 0.37333333333333335%\n",
      "progress = 0.4%\n",
      "progress = 0.4266666666666667%\n",
      "progress = 0.4533333333333333%\n",
      "progress = 0.48%\n",
      "progress = 0.5066666666666667%\n",
      "progress = 0.5333333333333333%\n",
      "progress = 0.56%\n",
      "progress = 0.5866666666666667%\n",
      "progress = 0.6133333333333333%\n",
      "progress = 0.64%\n",
      "progress = 0.6666666666666666%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-32fc845b61bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mraman\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-079a34f51149>\u001b[0m in \u001b[0;36msplit_signal\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"progress = {100* pixel / x.shape[0]}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# poly approximation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreliminary_photo_approximation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpixel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpoly2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-7f3cf213cd48>\u001b[0m in \u001b[0;36mpreliminary_photo_approximation\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mgaussians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfit_gaussian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_gaussian2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mx_\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mgaussians\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-7f3cf213cd48>\u001b[0m in \u001b[0;36mfit_gaussian\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0mscale\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                         \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavenumbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mscale\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-7f3cf213cd48>\u001b[0m in \u001b[0;36mgaussian\u001b[0;34m(x, mu, sigma, scale)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit_fit_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_wavenumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_sigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "from os import path\n",
    "\n",
    "file_location2 = f\"{'/'.join(file_location.split('/')[:-2])}/approximated_curve_fit/\"\n",
    "os.makedirs(file_location2, exist_ok=True)\n",
    "\n",
    "shape = data[0][0].shape\n",
    "\n",
    "for j, (f, img) in enumerate(zip(filenames, data)):   \n",
    "    start = timeit.default_timer()\n",
    "    if path.exists(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman.npy'):\n",
    "        print(f'file already exist {file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman')\n",
    "        continue\n",
    "    \n",
    "    raman, photo = split_signal(img)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', stop - start)  \n",
    "\n",
    "    np.save(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_raman', raman.reshape(shape))\n",
    "    np.save(f'{file_location2}{f.split(\"/\")[-1].split(\".\")[0]}_photoluminescence', photo.reshape(shape))\n",
    "    print(f\"image: {f} is done.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff9fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2971aefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea4274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
