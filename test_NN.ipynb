{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7912fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataset_utils as dataset\n",
    "import utils.train_utils as train\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89038785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector_norm(X):\n",
    "    return (X.T / np.sqrt((X**2).sum(axis=1))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b097b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"../data/Raman_Mouse/approximated/\"\n",
    "filenames = np.load(f\"{file_location}FileNames.npy\")\n",
    "with open(f'{file_location}Sample_labels.pickle', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "data = []\n",
    "for f in filenames:\n",
    "    try:\n",
    "        x = np.load(f\"{file_location}{f.split('.')[0]}_raman.npy\")\n",
    "        data.append((unit_vector_norm(x.reshape(-1,x.shape[-1])).reshape(x.shape), labels[f]))\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3266e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, size=1300*7*7 , output=10, depth=2, neurons=1300, bias=True, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential( \n",
    "            nn.Dropout3d(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(size, neurons, bias=bias),\n",
    "            nn.ReLU(True),\n",
    "            *((nn.Linear(neurons, neurons, bias=bias),\n",
    "            nn.ReLU(True)) * (depth-1)),\n",
    "            nn.Linear(neurons, 100, bias=bias),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100, output, bias=bias)\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfbbe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedClassifier(BaseEstimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        _use_cuda = torch.cuda.is_available() and kwargs['cuda']\n",
    "        if _use_cuda:\n",
    "            torch.backends.cudnn.enabled = True\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        self.device = torch.device('cuda' if _use_cuda else 'cpu')        \n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.model = MLP(**self.kwargs).to(self.device)\n",
    "\n",
    "        parameters = filter(lambda x: x.requires_grad, self.model.parameters())\n",
    "        self.optimizer = optim.Adam(parameters, lr=0.001)        \n",
    "        train_loader, test_loader = dataset.load_liver(data, self.kwargs['batch_size'], self.kwargs['patch_size'])\n",
    "        \n",
    "        for epoch in range(self.kwargs['epochs']):\n",
    "            print('-'*50)\n",
    "            print('Epoch {:3d}/{:3d}'.format(epoch+1, self.kwargs['epochs']))\n",
    "            start_time = datetime.now()\n",
    "            train.train(self.model, self.optimizer, train_loader, self.kwargs['loss_func'], self.kwargs['acc_func'], self.kwargs['log_step'], self.device)\n",
    "            end_time = datetime.now()\n",
    "            time_diff = relativedelta(end_time, start_time)\n",
    "            print('Elapsed time: {}h {}m {}s'.format(time_diff.hours, time_diff.minutes, time_diff.seconds))\n",
    "            loss = train.test(self.model, test_loader, self.kwargs['loss_func'], self.kwargs['acc_func'], self.device)\n",
    "            print('Validation| bits: {:2.2f}'.format(loss), flush=True)    \n",
    "                         \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict transforms the data into the reference space. Min weight should be 0 or higher then 'min_weight'\n",
    "        The error is the NMSE, where the MSE is normalised by the signal strength. \n",
    "        error.shape = X.shape[0], so for each data point the error is calculated.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "#         self.model(X)\n",
    "        \n",
    "#         return RCA_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9eba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCEWithLogitsLoss()\n",
    "def loss_func(y, y_):\n",
    "    y = y[0][:,:-1].to(y_.device) \n",
    "    return loss(y, y_)\n",
    "\n",
    "def acc_func(y, y_):\n",
    "    return np.mean((y[0][:,:-1].to(y_.device) == torch.round(torch.sigmoid(y_))).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d46ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "PATCH_SIZE = 7\n",
    "\n",
    "kwargs = {'size': PATCH_SIZE*PATCH_SIZE*data[0][0].shape[-1],\n",
    "          'batch_size': BATCH_SIZE,\n",
    "          'patch_size': PATCH_SIZE,\n",
    "          'cuda': True,\n",
    "          'log_step': 50,\n",
    "          'epochs': EPOCHS,\n",
    "          'depth': 4,\n",
    "          'output': 4,\n",
    "          'loss_func': loss_func,\n",
    "          'acc_func' : acc_func,\n",
    "          'neurons': data[0][0].shape[-1],\n",
    "          'bias': True\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66768a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvc = SupervisedClassifier(**kwargs)\n",
    "rvc.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fc3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
