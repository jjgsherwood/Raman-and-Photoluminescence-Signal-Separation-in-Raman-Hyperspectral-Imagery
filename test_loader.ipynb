{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1340abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataset_utils as dataset\n",
    "import utils.train_utils as train\n",
    "import preprocessing.GSP as GSP\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26aadd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"../data/HSI/Liver_map_150z25_60s_1TCPOBOP.npy\",\n",
    "             \"../data/HSI/Liver_map_150z25_60s_2TCPOBOP.npy\",\n",
    "             \"../data/HSI/Liver_map_150z25_60s_3OBOB.npy\"]\n",
    "data = []\n",
    "for f in filenames:\n",
    "    data.append(np.load(f))\n",
    "\n",
    "# assume linear increase in wavelength \n",
    "wavelength = list(range(data[0].shape[2]))\n",
    "shape = data[0].shape\n",
    "\n",
    "# raman_data = []\n",
    "# photo_data = []\n",
    "# for x in data:\n",
    "#     tmp = copy.copy(x.reshape(-1, x.shape[-1]))\n",
    "#     tmp1, tmp2 = GSP.split_Raman_af(GSP.smoothing(tmp), wavelength)\n",
    "#     raman_data.append(tmp1)\n",
    "#     photo_data.append(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88febd05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([64, 1, 5, 5, 1000])\n",
      "1 torch.Size([64, 1, 5, 5, 1000])\n",
      "2 torch.Size([64, 1, 5, 5, 1000])\n",
      "3 torch.Size([64, 1, 5, 5, 1000])\n",
      "4 torch.Size([64, 1, 5, 5, 1000])\n",
      "5 torch.Size([64, 1, 5, 5, 1000])\n",
      "6 torch.Size([64, 1, 5, 5, 1000])\n",
      "7 torch.Size([64, 1, 5, 5, 1000])\n",
      "8 torch.Size([64, 1, 5, 5, 1000])\n",
      "9 torch.Size([64, 1, 5, 5, 1000])\n",
      "10 torch.Size([64, 1, 5, 5, 1000])\n",
      "11 torch.Size([64, 1, 5, 5, 1000])\n",
      "12 torch.Size([64, 1, 5, 5, 1000])\n",
      "13 torch.Size([64, 1, 5, 5, 1000])\n",
      "14 torch.Size([64, 1, 5, 5, 1000])\n",
      "15 torch.Size([64, 1, 5, 5, 1000])\n",
      "16 torch.Size([64, 1, 5, 5, 1000])\n",
      "17 torch.Size([64, 1, 5, 5, 1000])\n",
      "18 torch.Size([64, 1, 5, 5, 1000])\n",
      "19 torch.Size([64, 1, 5, 5, 1000])\n",
      "20 torch.Size([64, 1, 5, 5, 1000])\n",
      "21 torch.Size([64, 1, 5, 5, 1000])\n",
      "22 torch.Size([64, 1, 5, 5, 1000])\n",
      "23 torch.Size([64, 1, 5, 5, 1000])\n",
      "24 torch.Size([64, 1, 5, 5, 1000])\n",
      "25 torch.Size([64, 1, 5, 5, 1000])\n",
      "26 torch.Size([64, 1, 5, 5, 1000])\n",
      "27 torch.Size([64, 1, 5, 5, 1000])\n",
      "28 torch.Size([64, 1, 5, 5, 1000])\n",
      "29 torch.Size([64, 1, 5, 5, 1000])\n",
      "30 torch.Size([64, 1, 5, 5, 1000])\n",
      "31 torch.Size([64, 1, 5, 5, 1000])\n",
      "32 torch.Size([64, 1, 5, 5, 1000])\n",
      "33 torch.Size([64, 1, 5, 5, 1000])\n",
      "34 torch.Size([64, 1, 5, 5, 1000])\n",
      "35 torch.Size([64, 1, 5, 5, 1000])\n",
      "36 torch.Size([64, 1, 5, 5, 1000])\n",
      "37 torch.Size([64, 1, 5, 5, 1000])\n",
      "38 torch.Size([64, 1, 5, 5, 1000])\n",
      "39 torch.Size([64, 1, 5, 5, 1000])\n",
      "40 torch.Size([64, 1, 5, 5, 1000])\n",
      "41 torch.Size([64, 1, 5, 5, 1000])\n",
      "42 torch.Size([64, 1, 5, 5, 1000])\n",
      "43 torch.Size([64, 1, 5, 5, 1000])\n",
      "44 torch.Size([64, 1, 5, 5, 1000])\n",
      "45 torch.Size([64, 1, 5, 5, 1000])\n",
      "46 torch.Size([64, 1, 5, 5, 1000])\n",
      "47 torch.Size([64, 1, 5, 5, 1000])\n",
      "48 torch.Size([64, 1, 5, 5, 1000])\n",
      "49 torch.Size([64, 1, 5, 5, 1000])\n",
      "50 torch.Size([64, 1, 5, 5, 1000])\n",
      "51 torch.Size([64, 1, 5, 5, 1000])\n",
      "52 torch.Size([64, 1, 5, 5, 1000])\n",
      "53 torch.Size([64, 1, 5, 5, 1000])\n",
      "54 torch.Size([64, 1, 5, 5, 1000])\n",
      "55 torch.Size([64, 1, 5, 5, 1000])\n",
      "56 torch.Size([64, 1, 5, 5, 1000])\n",
      "57 torch.Size([64, 1, 5, 5, 1000])\n",
      "58 torch.Size([64, 1, 5, 5, 1000])\n",
      "59 torch.Size([64, 1, 5, 5, 1000])\n",
      "60 torch.Size([64, 1, 5, 5, 1000])\n",
      "61 torch.Size([64, 1, 5, 5, 1000])\n",
      "62 torch.Size([64, 1, 5, 5, 1000])\n",
      "63 torch.Size([64, 1, 5, 5, 1000])\n",
      "64 torch.Size([64, 1, 5, 5, 1000])\n",
      "65 torch.Size([64, 1, 5, 5, 1000])\n",
      "66 torch.Size([64, 1, 5, 5, 1000])\n",
      "67 torch.Size([64, 1, 5, 5, 1000])\n",
      "68 torch.Size([64, 1, 5, 5, 1000])\n",
      "69 torch.Size([64, 1, 5, 5, 1000])\n",
      "70 torch.Size([64, 1, 5, 5, 1000])\n",
      "71 torch.Size([64, 1, 5, 5, 1000])\n",
      "72 torch.Size([64, 1, 5, 5, 1000])\n",
      "73 torch.Size([64, 1, 5, 5, 1000])\n",
      "74 torch.Size([64, 1, 5, 5, 1000])\n",
      "75 torch.Size([64, 1, 5, 5, 1000])\n",
      "76 torch.Size([64, 1, 5, 5, 1000])\n",
      "77 torch.Size([64, 1, 5, 5, 1000])\n",
      "78 torch.Size([64, 1, 5, 5, 1000])\n",
      "79 torch.Size([64, 1, 5, 5, 1000])\n",
      "80 torch.Size([64, 1, 5, 5, 1000])\n",
      "81 torch.Size([64, 1, 5, 5, 1000])\n",
      "82 torch.Size([64, 1, 5, 5, 1000])\n",
      "83 torch.Size([64, 1, 5, 5, 1000])\n",
      "84 torch.Size([64, 1, 5, 5, 1000])\n",
      "85 torch.Size([64, 1, 5, 5, 1000])\n",
      "86 torch.Size([64, 1, 5, 5, 1000])\n",
      "87 torch.Size([64, 1, 5, 5, 1000])\n",
      "88 torch.Size([64, 1, 5, 5, 1000])\n",
      "89 torch.Size([64, 1, 5, 5, 1000])\n",
      "90 torch.Size([40, 1, 5, 5, 1000])\n"
     ]
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "PATCH_SIZE = 5\n",
    "data = np.array(data)\n",
    "train_loader, test_loader = dataset.load_liver(data, BATCH_SIZE, PATCH_SIZE)\n",
    "\n",
    "for batch_idx, (x, *_) in enumerate(train_loader):\n",
    "    print(batch_idx, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d77302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedClassifier(BaseEstimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        self.ae_kwargs = {}\n",
    "        self.k_means_kwargs = {}                \n",
    "        self.set_params(**kwargs)\n",
    "\n",
    "        _use_cuda = torch.cuda.is_available() and kwargs['cuda']\n",
    "        if _use_cuda:\n",
    "            torch.backends.cudnn.enabled = True\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        self.device = torch.device('cuda' if _use_cuda else 'cpu')        \n",
    "        \n",
    "    def fit(self, x, **kwargs):\n",
    "        self.set_params(**kwargs)\n",
    "        X = unit_vector_norm(x)\n",
    "        \n",
    "        ###################### Autoencoder ################################\n",
    "        self.model = AutoEncoder(**self.ae_kwargs).to(self.device)\n",
    "        \n",
    "        parameters = filter(lambda x: x.requires_grad, self.model.parameters())\n",
    "        self.optimizer = optim.Adam(parameters)        \n",
    "        train_loader, test_loader = dataset.load_liver(X, self.kwargs['batch_size'])\n",
    "        \n",
    "        for epoch in range(self.kwargs['epochs']):\n",
    "            print('-'*50)\n",
    "            print('Epoch {:3d}/{:3d}'.format(epoch+1, self.kwargs['epochs']))\n",
    "            start_time = datetime.now()\n",
    "            train.train(self.model, self.optimizer, train_loader, self.kwargs['loss_func'], self.kwargs['log_step'], self.device)\n",
    "            end_time = datetime.now()\n",
    "            time_diff = relativedelta(end_time, start_time)\n",
    "            print('Elapsed time: {}h {}m {}s'.format(time_diff.hours, time_diff.minutes, time_diff.seconds))\n",
    "            loss = train.test(self.model, test_loader, self.kwargs['loss_func'], self.device)\n",
    "            print('Validation| bits: {:2.2f}'.format(loss), flush=True)    \n",
    "          \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            W = self.model.encode(dataset.load_liver_all(X).to(self.device))\n",
    "        self.z = W\n",
    "        W = W.cpu().detach().numpy()\n",
    "        \n",
    "        ###################### clustering ################################        \n",
    "        self.clusters = cluster.KMeans(**self.k_means_kwargs).fit(W)\n",
    "        self.clusters = self.clusters.labels_\n",
    "        \n",
    "        one_hot = np.zeros((X.shape[0], self.kwargs['n_clusters']), dtype=bool)\n",
    "        one_hot[range(X.shape[0]), self.clusters] = 1\n",
    "                          \n",
    "        ###################### reference spectra ################################\n",
    "        self.reference_spectra_ = unit_vector_norm(np.array([np.abs(x_) for i, x_ in enumerate(one_hot.T @ X)]))\n",
    "        self.ref_org = np.array([x[one_hot[:,i],:].mean(axis=0) for i in range(self.kwargs['n_clusters'])])\n",
    "               \n",
    "        # Return the classifier\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict transforms the data into the reference space. Min weight should be 0 or higher then 'min_weight'\n",
    "        The error is the NMSE, where the MSE is normalised by the signal strength. \n",
    "        error.shape = X.shape[0], so for each data point the error is calculated.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        X = unit_vector_norm(X)\n",
    "        \n",
    "        ###################### RCA ################################           \n",
    "        RCA_vector = np.array([optimize.nnls(self.reference_spectra_.T, X[i,:])[0] for i in range(X.shape[0])])\n",
    "\n",
    "        return RCA_vector\n",
    "    \n",
    "    def get_reference_vectors(self):\n",
    "        return self.reference_spectra_\n",
    "\n",
    "    def get_org_reference_vectors(self):\n",
    "        return self.ref_org    \n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return self.kwargs\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.kwargs.update(kwargs)\n",
    "        self.k_means_kwargs.update({k:v  for k,v in kwargs.items() if k in list(inspect.signature(cluster.KMeans).parameters.keys())})     \n",
    "        self.ae_kwargs.update({k:v  for k,v in kwargs.items() if k in list(inspect.signature(AutoEncoder).parameters.keys())})     \n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
